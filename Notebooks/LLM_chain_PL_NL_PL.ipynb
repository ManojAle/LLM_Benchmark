{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba26e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f319a9954654c04bb33274803a96c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(92416, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (k_proj): Linear(in_features=4096, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=4096, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=13440, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=13440, bias=False)\n",
       "          (down_proj): Linear(in_features=13440, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=92416, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path='/home/manojale/Documents/Performance_Dataset/New_project_proposal/Nxcode-CQ-7B-orpo/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83841d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "samples=pd.read_csv('Data/Verified_Samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339244d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>commit_url</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>diff_before</th>\n",
       "      <th>diff_after</th>\n",
       "      <th>diff</th>\n",
       "      <th>pred_primary</th>\n",
       "      <th>pred_secondary</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/fangfufu/Linux-Fake-Backgro...</td>\n",
       "      <td>Removing frame.flags.writeable = False Removin...</td>\n",
       "      <td>def compose_frame(self, frame):\\n  frame.flags...</td>\n",
       "      <td>def compose_frame(self, frame):\\n  mask = self...</td>\n",
       "      <td>@@ -292,7 +292,6 @@ then scale &amp; crop the imag...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/kugelrund/mesh_segmentation...</td>\n",
       "      <td>Improve performance of calculating graph lapla...</td>\n",
       "      <td>def segment_mesh(mesh, k, coefficients, action...</td>\n",
       "      <td>def segment_mesh(mesh, k, coefficients, action...</td>\n",
       "      <td>@@ -248,9 +248,9 @@ def segment_mesh(mesh, k, ...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/zama-ai/concrete-ml/commit/...</td>\n",
       "      <td>chore: improve performances of numpy_gemm clos...</td>\n",
       "      <td>def numpy_gemm(\\n  a: numpy.ndarray,\\n  b: num...</td>\n",
       "      <td>def numpy_gemm(\\n  a: numpy.ndarray,\\n  b: num...</td>\n",
       "      <td>@@ -117,7 +117,15 @@ def numpy_gemm(\\n  b_prim...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/urule99/jsunpack-n/commit/c...</td>\n",
       "      <td>pdf regex replaced with character processing t...</td>\n",
       "      <td>def applyFilter(input):\\n  output = re.sub('^[...</td>\n",
       "      <td>def applyFilter(input):\\n  if len(input) &gt; 100...</td>\n",
       "      <td>@@ -497,8 +497,29 @@ class pdf:\\n  \\n  @static...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>https://github.com/bayesianbandits/bayesianban...</td>\n",
       "      <td>MAINT: improve performance by removing unneces...</td>\n",
       "      <td>def decay(self, X: NDArray[Any]) -&gt; None:\\n  \"...</td>\n",
       "      <td>def decay(self, X: NDArray[Any]) -&gt; None:\\n  \"...</td>\n",
       "      <td>@@ -606,14 +606,12 @@ class NormalRegressor(Ba...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>https://github.com/pygae/clifford/commit/36b59...</td>\n",
       "      <td>Improve performance of arithmetic on MultiVect...</td>\n",
       "      <td>def _checkOther(self, other, coerce=True) -&gt; T...</td>\n",
       "      <td>def _checkOther(self, other, coerce=True) -&gt; T...</td>\n",
       "      <td>@@ -61,7 +61,13 @@ class MultiVector(object):\\...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Expensive_Operation</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>https://github.com/optuna/optuna/commit/dd3ede...</td>\n",
       "      <td>Make set_trial_param() of RedisStorage faster ...</td>\n",
       "      <td>def set_trial_param(\\n  self,\\n  trial_id: int...</td>\n",
       "      <td>def set_trial_param(\\n  self,\\n  trial_id: int...</td>\n",
       "      <td>@@ -1,3 +1,4 @@\\n +from collections.abc import...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>https://github.com/DingGuodong/LinuxBashShellS...</td>\n",
       "      <td>improve performance and cut down time user wait</td>\n",
       "      <td>def getServiceName(self, name):\\n  if isinstan...</td>\n",
       "      <td>def getServiceName(self, name):\\n  if isinstan...</td>\n",
       "      <td>@@ -84,9 +84,8 @@ class remoteWindowsWMI(objec...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>https://github.com/bartfeenstra/betty/commit/4...</td>\n",
       "      <td>Link instead of copy rendered files to improve...</td>\n",
       "      <td>def _filter_file(site: Site, file: File) -&gt; st...</td>\n",
       "      <td>def _filter_file(site: Site, file: File) -&gt; st...</td>\n",
       "      <td>@@ -266,7 +266,7 @@ def _filter_file(site: Sit...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>https://github.com/arangodb/python-arango/comm...</td>\n",
       "      <td>[PERF] improve performance of large batch commits</td>\n",
       "      <td>def commit(self):\\n  \"\"\"Execute the queued API...</td>\n",
       "      <td>def commit(self):\\n  \"\"\"Execute the queued API...</td>\n",
       "      <td>@@ -104,13 +104,14 @@ class BatchExecution(Con...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>https://github.com/rapidpro/rapidpro/commit/bc...</td>\n",
       "      <td>Improve performance of contact searches by loc...</td>\n",
       "      <td>def generate_location_field_comparison(field, ...</td>\n",
       "      <td>def generate_location_field_comparison(field, ...</td>\n",
       "      <td>@@ -10,6 +10,7 @@ from decimal import Decimal\\...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>https://github.com/rapidpro/rapidpro/commit/99...</td>\n",
       "      <td>Improve performance of migration to populate f...</td>\n",
       "      <td>def populate_flowrun_uuid(FlowRun):\\n  run_ids...</td>\n",
       "      <td>def populate_flowrun_uuid(FlowRun):\\n  with co...</td>\n",
       "      <td>@@ -2,23 +2,27 @@\\n  # Generated by Django 1.1...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>https://github.com/optuna/optuna/commit/3b2f80...</td>\n",
       "      <td>Make _set_best_trial() of RedisStorage faster ...</td>\n",
       "      <td>def _set_best_trial(self, study_id: int, trial...</td>\n",
       "      <td>def _set_best_trial(self, study_id: int, trial...</td>\n",
       "      <td>@@ -534,14 +534,15 @@ class RedisStorage(BaseS...</td>\n",
       "      <td>Inefficient_I/O</td>\n",
       "      <td>Inefficient_Disk_I/O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>https://github.com/0xInfection/XSRFProbe/commi...</td>\n",
       "      <td>Added some fixes to improve performance improv...</td>\n",
       "      <td>def Analysis():\\n  '''\\n  The main idea behind...</td>\n",
       "      <td>def Analysis():\\n  '''\\n  The main idea behind...</td>\n",
       "      <td>@@ -10,7 +10,7 @@\\n  # https://github.com/0xIn...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Misc._Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>https://github.com/TabbycatDebate/tabbycat/com...</td>\n",
       "      <td>Add selections to Team Viewset To improve perf...</td>\n",
       "      <td>def get_queryset(self):\\n  return super().get_...</td>\n",
       "      <td>def get_queryset(self):\\n  return super().get_...</td>\n",
       "      <td>@@ -81,7 +81,6 @@ class RoundViewSet(Tournamen...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Misc._Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>https://github.com/getsentry/sentry/commit/239...</td>\n",
       "      <td>perf(group_owners): Improve performance of `ge...</td>\n",
       "      <td>def get_previous_releases(project, start_versi...</td>\n",
       "      <td>def get_previous_releases(project, start_versi...</td>\n",
       "      <td>@@ -154,26 +154,43 @@ def get_previous_release...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Misc._Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>https://github.com/prometheus-community/node-e...</td>\n",
       "      <td>btrfs_stats.py: Precompiled regular expression...</td>\n",
       "      <td>def get_btrfs_errors(mountpoint):\\n  \"\"\"Get pe...</td>\n",
       "      <td>def get_btrfs_errors(mountpoint):\\n  \"\"\"Get pe...</td>\n",
       "      <td>@@ -12,6 +12,9 @@ import subprocess\\n  from pr...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Misc._Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>https://github.com/comic/grand-challenge.org/c...</td>\n",
       "      <td>Improve performance of db query (#2444) This s...</td>\n",
       "      <td>def update_viewer_groups_permissions(self, *, ...</td>\n",
       "      <td>def update_viewer_groups_permissions(self, *, ...</td>\n",
       "      <td>@@ -6,11 +6,9 @@ from typing import List\\n  fr...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Misc._Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>https://github.com/google/deepvariant/commit/8...</td>\n",
       "      <td>Improve performance by using synchronous VCF w...</td>\n",
       "      <td>def write_variants_to_vcf(contigs,\\n  variant_...</td>\n",
       "      <td>def write_variants_to_vcf(contigs,\\n  variant_...</td>\n",
       "      <td>@@ -613,9 +613,9 @@ def write_variants_to_vcf(...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>https://github.com/cryzed/Selenium-Requests/co...</td>\n",
       "      <td>Improve performance by using a session object ...</td>\n",
       "      <td>def request(self, method, url, **kwargs):\\n  #...</td>\n",
       "      <td>def request(self, method, url, **kwargs):\\n  #...</td>\n",
       "      <td>@@ -131,13 +131,9 @@ class RequestMixin(object...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>https://github.com/emonti/qualcomm-opensource-...</td>\n",
       "      <td>linux-ramdump-parser-v2: Optimize taskdump pan...</td>\n",
       "      <td>def dump_thread_group(ramdump, thread_group, t...</td>\n",
       "      <td>def dump_thread_group(ramdump, thread_group, t...</td>\n",
       "      <td>@@ -1,4 +1,4 @@\\n -# Copyright (c) 2012-2013, ...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>https://github.com/spotify/cstar/commit/fd4cfd...</td>\n",
       "      <td>Improve performance of \"Preheating DNS cache\" ...</td>\n",
       "      <td>def reverse_dns_preheat(self, ips):\\n  if self...</td>\n",
       "      <td>def reverse_dns_preheat(self, ips):\\n  if self...</td>\n",
       "      <td>@@ -156,7 +156,7 @@ class Job(object):\\n  retu...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>https://github.com/sosreport/sos/commit/658148...</td>\n",
       "      <td>[sosreport] do not pass chunksize to ThreadPoo...</td>\n",
       "      <td>def collect(self):\\n  self.ui_log.info(_(\" Run...</td>\n",
       "      <td>def collect(self):\\n  self.ui_log.info(_(\" Run...</td>\n",
       "      <td>@@ -973,7 +973,7 @@ class SoSReport(object):\\n...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>https://github.com/cocotb/cocotb/commit/255ce4...</td>\n",
       "      <td>Avoiding doing two dictionary lookups when one...</td>\n",
       "      <td>def _event_loop(self, trigger):\\n  \"\"\"\\n  Run ...</td>\n",
       "      <td>def _event_loop(self, trigger):\\n  \"\"\"\\n  Run ...</td>\n",
       "      <td>@@ -398,8 +398,11 @@ class Scheduler(object):\\...</td>\n",
       "      <td>Poor_Concurrency_Control</td>\n",
       "      <td>Unnecessary_Thread_Synchronization</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>https://github.com/hydpy-dev/hydpy/commit/af66...</td>\n",
       "      <td>Improve performance of class `IntegrationTest`...</td>\n",
       "      <td>def print_table(self, idx1=None, idx2=None):\\n...</td>\n",
       "      <td>def print_table(self, idx1=None, idx2=None):\\n...</td>\n",
       "      <td>@@ -188,14 +188,16 @@ class Test(object):\\n  \\...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>https://github.com/robcaulk/freqai/commit/fc21...</td>\n",
       "      <td>move experimental eval below stop_loss_reached...</td>\n",
       "      <td>def should_sell(self, trade: Trade, rate: floa...</td>\n",
       "      <td>def should_sell(self, trade: Trade, rate: floa...</td>\n",
       "      <td>@@ -173,10 +173,11 @@ class Analyze(object):\\n...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34</td>\n",
       "      <td>https://github.com/ietf-tools/datatracker/comm...</td>\n",
       "      <td>Improve performance of many document list page...</td>\n",
       "      <td>def expirable_draft(draft):\\n  \"\"\"Return wheth...</td>\n",
       "      <td>def expirable_draft(draft):\\n  \"\"\"Return wheth...</td>\n",
       "      <td>@@ -28,7 +28,6 @@ def expirable_draft(draft):\\...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35</td>\n",
       "      <td>https://github.com/dpgaspar/Flask-AppBuilder/c...</td>\n",
       "      <td>fix: improve performance for get role permissi...</td>\n",
       "      <td>def get_db_role_permissions(self, role_id: int...</td>\n",
       "      <td>def get_db_role_permissions(self, role_id: int...</td>\n",
       "      <td>@@ -4,6 +4,7 @@ import uuid\\n  \\n  from sqlalc...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36</td>\n",
       "      <td>https://github.com/ecdavis/pants/commit/8a60b1...</td>\n",
       "      <td>Minor change to HTTPRequest that should improv...</td>\n",
       "      <td>def _parse_uri(self):\\n  path, query = urlpars...</td>\n",
       "      <td>def _parse_uri(self):\\n  path, query = urlpars...</td>\n",
       "      <td>@@ -502,7 +502,7 @@ class HTTPRequest(object):...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38</td>\n",
       "      <td>https://github.com/irrdnet/irrd/commit/f53bcae...</td>\n",
       "      <td>Ref #19 - Improve performance of !6/!g queries...</td>\n",
       "      <td>def _routes_for_origin(self, object_class: str...</td>\n",
       "      <td>def _routes_for_origin(self, object_class: str...</td>\n",
       "      <td>@@ -169,12 +169,7 @@ class WhoisQueryParser:\\n...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>39</td>\n",
       "      <td>https://github.com/cardinalitypuzzles/cardboar...</td>\n",
       "      <td>improve performance of default puzzle tag popu...</td>\n",
       "      <td>def create_default_tags(hunt):\\n  for (name, c...</td>\n",
       "      <td>def create_default_tags(hunt):\\n  default_tag_...</td>\n",
       "      <td>@@ -105,16 +105,32 @@ class PuzzleTag(models.M...</td>\n",
       "      <td>Inefficient_Algorithm/Data-structure</td>\n",
       "      <td>Unnecessary_computations</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         commit_url  \\\n",
       "0            0  https://github.com/fangfufu/Linux-Fake-Backgro...   \n",
       "1            1  https://github.com/kugelrund/mesh_segmentation...   \n",
       "2            3  https://github.com/zama-ai/concrete-ml/commit/...   \n",
       "3            4  https://github.com/urule99/jsunpack-n/commit/c...   \n",
       "4            6  https://github.com/bayesianbandits/bayesianban...   \n",
       "5            7  https://github.com/pygae/clifford/commit/36b59...   \n",
       "6            8  https://github.com/optuna/optuna/commit/dd3ede...   \n",
       "7            9  https://github.com/DingGuodong/LinuxBashShellS...   \n",
       "8           10  https://github.com/bartfeenstra/betty/commit/4...   \n",
       "9           11  https://github.com/arangodb/python-arango/comm...   \n",
       "10          12  https://github.com/rapidpro/rapidpro/commit/bc...   \n",
       "11          13  https://github.com/rapidpro/rapidpro/commit/99...   \n",
       "12          14  https://github.com/optuna/optuna/commit/3b2f80...   \n",
       "13          17  https://github.com/0xInfection/XSRFProbe/commi...   \n",
       "14          19  https://github.com/TabbycatDebate/tabbycat/com...   \n",
       "15          20  https://github.com/getsentry/sentry/commit/239...   \n",
       "16          21  https://github.com/prometheus-community/node-e...   \n",
       "17          22  https://github.com/comic/grand-challenge.org/c...   \n",
       "18          24  https://github.com/google/deepvariant/commit/8...   \n",
       "19          25  https://github.com/cryzed/Selenium-Requests/co...   \n",
       "20          27  https://github.com/emonti/qualcomm-opensource-...   \n",
       "21          29  https://github.com/spotify/cstar/commit/fd4cfd...   \n",
       "22          30  https://github.com/sosreport/sos/commit/658148...   \n",
       "23          31  https://github.com/cocotb/cocotb/commit/255ce4...   \n",
       "24          32  https://github.com/hydpy-dev/hydpy/commit/af66...   \n",
       "25          33  https://github.com/robcaulk/freqai/commit/fc21...   \n",
       "26          34  https://github.com/ietf-tools/datatracker/comm...   \n",
       "27          35  https://github.com/dpgaspar/Flask-AppBuilder/c...   \n",
       "28          36  https://github.com/ecdavis/pants/commit/8a60b1...   \n",
       "29          38  https://github.com/irrdnet/irrd/commit/f53bcae...   \n",
       "30          39  https://github.com/cardinalitypuzzles/cardboar...   \n",
       "\n",
       "                                       commit_message  \\\n",
       "0   Removing frame.flags.writeable = False Removin...   \n",
       "1   Improve performance of calculating graph lapla...   \n",
       "2   chore: improve performances of numpy_gemm clos...   \n",
       "3   pdf regex replaced with character processing t...   \n",
       "4   MAINT: improve performance by removing unneces...   \n",
       "5   Improve performance of arithmetic on MultiVect...   \n",
       "6   Make set_trial_param() of RedisStorage faster ...   \n",
       "7     improve performance and cut down time user wait   \n",
       "8   Link instead of copy rendered files to improve...   \n",
       "9   [PERF] improve performance of large batch commits   \n",
       "10  Improve performance of contact searches by loc...   \n",
       "11  Improve performance of migration to populate f...   \n",
       "12  Make _set_best_trial() of RedisStorage faster ...   \n",
       "13  Added some fixes to improve performance improv...   \n",
       "14  Add selections to Team Viewset To improve perf...   \n",
       "15  perf(group_owners): Improve performance of `ge...   \n",
       "16  btrfs_stats.py: Precompiled regular expression...   \n",
       "17  Improve performance of db query (#2444) This s...   \n",
       "18  Improve performance by using synchronous VCF w...   \n",
       "19  Improve performance by using a session object ...   \n",
       "20  linux-ramdump-parser-v2: Optimize taskdump pan...   \n",
       "21  Improve performance of \"Preheating DNS cache\" ...   \n",
       "22  [sosreport] do not pass chunksize to ThreadPoo...   \n",
       "23  Avoiding doing two dictionary lookups when one...   \n",
       "24  Improve performance of class `IntegrationTest`...   \n",
       "25  move experimental eval below stop_loss_reached...   \n",
       "26  Improve performance of many document list page...   \n",
       "27  fix: improve performance for get role permissi...   \n",
       "28  Minor change to HTTPRequest that should improv...   \n",
       "29  Ref #19 - Improve performance of !6/!g queries...   \n",
       "30  improve performance of default puzzle tag popu...   \n",
       "\n",
       "                                          diff_before  \\\n",
       "0   def compose_frame(self, frame):\\n  frame.flags...   \n",
       "1   def segment_mesh(mesh, k, coefficients, action...   \n",
       "2   def numpy_gemm(\\n  a: numpy.ndarray,\\n  b: num...   \n",
       "3   def applyFilter(input):\\n  output = re.sub('^[...   \n",
       "4   def decay(self, X: NDArray[Any]) -> None:\\n  \"...   \n",
       "5   def _checkOther(self, other, coerce=True) -> T...   \n",
       "6   def set_trial_param(\\n  self,\\n  trial_id: int...   \n",
       "7   def getServiceName(self, name):\\n  if isinstan...   \n",
       "8   def _filter_file(site: Site, file: File) -> st...   \n",
       "9   def commit(self):\\n  \"\"\"Execute the queued API...   \n",
       "10  def generate_location_field_comparison(field, ...   \n",
       "11  def populate_flowrun_uuid(FlowRun):\\n  run_ids...   \n",
       "12  def _set_best_trial(self, study_id: int, trial...   \n",
       "13  def Analysis():\\n  '''\\n  The main idea behind...   \n",
       "14  def get_queryset(self):\\n  return super().get_...   \n",
       "15  def get_previous_releases(project, start_versi...   \n",
       "16  def get_btrfs_errors(mountpoint):\\n  \"\"\"Get pe...   \n",
       "17  def update_viewer_groups_permissions(self, *, ...   \n",
       "18  def write_variants_to_vcf(contigs,\\n  variant_...   \n",
       "19  def request(self, method, url, **kwargs):\\n  #...   \n",
       "20  def dump_thread_group(ramdump, thread_group, t...   \n",
       "21  def reverse_dns_preheat(self, ips):\\n  if self...   \n",
       "22  def collect(self):\\n  self.ui_log.info(_(\" Run...   \n",
       "23  def _event_loop(self, trigger):\\n  \"\"\"\\n  Run ...   \n",
       "24  def print_table(self, idx1=None, idx2=None):\\n...   \n",
       "25  def should_sell(self, trade: Trade, rate: floa...   \n",
       "26  def expirable_draft(draft):\\n  \"\"\"Return wheth...   \n",
       "27  def get_db_role_permissions(self, role_id: int...   \n",
       "28  def _parse_uri(self):\\n  path, query = urlpars...   \n",
       "29  def _routes_for_origin(self, object_class: str...   \n",
       "30  def create_default_tags(hunt):\\n  for (name, c...   \n",
       "\n",
       "                                           diff_after  \\\n",
       "0   def compose_frame(self, frame):\\n  mask = self...   \n",
       "1   def segment_mesh(mesh, k, coefficients, action...   \n",
       "2   def numpy_gemm(\\n  a: numpy.ndarray,\\n  b: num...   \n",
       "3   def applyFilter(input):\\n  if len(input) > 100...   \n",
       "4   def decay(self, X: NDArray[Any]) -> None:\\n  \"...   \n",
       "5   def _checkOther(self, other, coerce=True) -> T...   \n",
       "6   def set_trial_param(\\n  self,\\n  trial_id: int...   \n",
       "7   def getServiceName(self, name):\\n  if isinstan...   \n",
       "8   def _filter_file(site: Site, file: File) -> st...   \n",
       "9   def commit(self):\\n  \"\"\"Execute the queued API...   \n",
       "10  def generate_location_field_comparison(field, ...   \n",
       "11  def populate_flowrun_uuid(FlowRun):\\n  with co...   \n",
       "12  def _set_best_trial(self, study_id: int, trial...   \n",
       "13  def Analysis():\\n  '''\\n  The main idea behind...   \n",
       "14  def get_queryset(self):\\n  return super().get_...   \n",
       "15  def get_previous_releases(project, start_versi...   \n",
       "16  def get_btrfs_errors(mountpoint):\\n  \"\"\"Get pe...   \n",
       "17  def update_viewer_groups_permissions(self, *, ...   \n",
       "18  def write_variants_to_vcf(contigs,\\n  variant_...   \n",
       "19  def request(self, method, url, **kwargs):\\n  #...   \n",
       "20  def dump_thread_group(ramdump, thread_group, t...   \n",
       "21  def reverse_dns_preheat(self, ips):\\n  if self...   \n",
       "22  def collect(self):\\n  self.ui_log.info(_(\" Run...   \n",
       "23  def _event_loop(self, trigger):\\n  \"\"\"\\n  Run ...   \n",
       "24  def print_table(self, idx1=None, idx2=None):\\n...   \n",
       "25  def should_sell(self, trade: Trade, rate: floa...   \n",
       "26  def expirable_draft(draft):\\n  \"\"\"Return wheth...   \n",
       "27  def get_db_role_permissions(self, role_id: int...   \n",
       "28  def _parse_uri(self):\\n  path, query = urlpars...   \n",
       "29  def _routes_for_origin(self, object_class: str...   \n",
       "30  def create_default_tags(hunt):\\n  default_tag_...   \n",
       "\n",
       "                                                 diff  \\\n",
       "0   @@ -292,7 +292,6 @@ then scale & crop the imag...   \n",
       "1   @@ -248,9 +248,9 @@ def segment_mesh(mesh, k, ...   \n",
       "2   @@ -117,7 +117,15 @@ def numpy_gemm(\\n  b_prim...   \n",
       "3   @@ -497,8 +497,29 @@ class pdf:\\n  \\n  @static...   \n",
       "4   @@ -606,14 +606,12 @@ class NormalRegressor(Ba...   \n",
       "5   @@ -61,7 +61,13 @@ class MultiVector(object):\\...   \n",
       "6   @@ -1,3 +1,4 @@\\n +from collections.abc import...   \n",
       "7   @@ -84,9 +84,8 @@ class remoteWindowsWMI(objec...   \n",
       "8   @@ -266,7 +266,7 @@ def _filter_file(site: Sit...   \n",
       "9   @@ -104,13 +104,14 @@ class BatchExecution(Con...   \n",
       "10  @@ -10,6 +10,7 @@ from decimal import Decimal\\...   \n",
       "11  @@ -2,23 +2,27 @@\\n  # Generated by Django 1.1...   \n",
       "12  @@ -534,14 +534,15 @@ class RedisStorage(BaseS...   \n",
       "13  @@ -10,7 +10,7 @@\\n  # https://github.com/0xIn...   \n",
       "14  @@ -81,7 +81,6 @@ class RoundViewSet(Tournamen...   \n",
       "15  @@ -154,26 +154,43 @@ def get_previous_release...   \n",
       "16  @@ -12,6 +12,9 @@ import subprocess\\n  from pr...   \n",
       "17  @@ -6,11 +6,9 @@ from typing import List\\n  fr...   \n",
       "18  @@ -613,9 +613,9 @@ def write_variants_to_vcf(...   \n",
       "19  @@ -131,13 +131,9 @@ class RequestMixin(object...   \n",
       "20  @@ -1,4 +1,4 @@\\n -# Copyright (c) 2012-2013, ...   \n",
       "21  @@ -156,7 +156,7 @@ class Job(object):\\n  retu...   \n",
       "22  @@ -973,7 +973,7 @@ class SoSReport(object):\\n...   \n",
       "23  @@ -398,8 +398,11 @@ class Scheduler(object):\\...   \n",
       "24  @@ -188,14 +188,16 @@ class Test(object):\\n  \\...   \n",
       "25  @@ -173,10 +173,11 @@ class Analyze(object):\\n...   \n",
       "26  @@ -28,7 +28,6 @@ def expirable_draft(draft):\\...   \n",
       "27  @@ -4,6 +4,7 @@ import uuid\\n  \\n  from sqlalc...   \n",
       "28  @@ -502,7 +502,7 @@ class HTTPRequest(object):...   \n",
       "29  @@ -169,12 +169,7 @@ class WhoisQueryParser:\\n...   \n",
       "30  @@ -105,16 +105,32 @@ class PuzzleTag(models.M...   \n",
       "\n",
       "                            pred_primary  \\\n",
       "0   Inefficient_Algorithm/Data-structure   \n",
       "1   Inefficient_Algorithm/Data-structure   \n",
       "2   Inefficient_Algorithm/Data-structure   \n",
       "3   Inefficient_Algorithm/Data-structure   \n",
       "4   Inefficient_Algorithm/Data-structure   \n",
       "5   Inefficient_Algorithm/Data-structure   \n",
       "6                        Inefficient_I/O   \n",
       "7                        Inefficient_I/O   \n",
       "8                        Inefficient_I/O   \n",
       "9                        Inefficient_I/O   \n",
       "10                       Inefficient_I/O   \n",
       "11                       Inefficient_I/O   \n",
       "12                       Inefficient_I/O   \n",
       "13  Inefficient_Algorithm/Data-structure   \n",
       "14  Inefficient_Algorithm/Data-structure   \n",
       "15  Inefficient_Algorithm/Data-structure   \n",
       "16  Inefficient_Algorithm/Data-structure   \n",
       "17  Inefficient_Algorithm/Data-structure   \n",
       "18              Poor_Concurrency_Control   \n",
       "19              Poor_Concurrency_Control   \n",
       "20              Poor_Concurrency_Control   \n",
       "21              Poor_Concurrency_Control   \n",
       "22              Poor_Concurrency_Control   \n",
       "23              Poor_Concurrency_Control   \n",
       "24  Inefficient_Algorithm/Data-structure   \n",
       "25  Inefficient_Algorithm/Data-structure   \n",
       "26  Inefficient_Algorithm/Data-structure   \n",
       "27  Inefficient_Algorithm/Data-structure   \n",
       "28  Inefficient_Algorithm/Data-structure   \n",
       "29  Inefficient_Algorithm/Data-structure   \n",
       "30  Inefficient_Algorithm/Data-structure   \n",
       "\n",
       "                                pred_secondary Quality  \n",
       "0                          Expensive_Operation    good  \n",
       "1                          Expensive_Operation    good  \n",
       "2                          Expensive_Operation    good  \n",
       "3                          Expensive_Operation    good  \n",
       "4                          Expensive_Operation    good  \n",
       "5                          Expensive_Operation    good  \n",
       "6                         Inefficient_Disk_I/O    good  \n",
       "7                         Inefficient_Disk_I/O    good  \n",
       "8                         Inefficient_Disk_I/O    good  \n",
       "9                         Inefficient_Disk_I/O    good  \n",
       "10                        Inefficient_Disk_I/O    good  \n",
       "11                        Inefficient_Disk_I/O    good  \n",
       "12                        Inefficient_Disk_I/O    good  \n",
       "13  Misc._Inefficient_Algorithm/Data-structure    good  \n",
       "14  Misc._Inefficient_Algorithm/Data-structure    good  \n",
       "15  Misc._Inefficient_Algorithm/Data-structure    good  \n",
       "16  Misc._Inefficient_Algorithm/Data-structure    good  \n",
       "17  Misc._Inefficient_Algorithm/Data-structure    good  \n",
       "18          Unnecessary_Thread_Synchronization    good  \n",
       "19          Unnecessary_Thread_Synchronization    good  \n",
       "20          Unnecessary_Thread_Synchronization    good  \n",
       "21          Unnecessary_Thread_Synchronization    good  \n",
       "22          Unnecessary_Thread_Synchronization    good  \n",
       "23          Unnecessary_Thread_Synchronization    good  \n",
       "24                    Unnecessary_computations    good  \n",
       "25                    Unnecessary_computations    good  \n",
       "26                    Unnecessary_computations    good  \n",
       "27                    Unnecessary_computations    good  \n",
       "28                    Unnecessary_computations    good  \n",
       "29                    Unnecessary_computations    good  \n",
       "30                    Unnecessary_computations    good  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef21bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "Processing 20\n",
      "Processing 21\n",
      "Processing 22\n",
      "Processing 23\n",
      "Processing 24\n",
      "Processing 25\n",
      "Processing 26\n",
      "Processing 27\n",
      "Processing 28\n",
      "Processing 29\n",
      "Processing 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "temp_df=samples\n",
    "\n",
    "batched_predictions = []\n",
    "\n",
    "# Your provided prompt template\n",
    "prompt_template = '''\n",
    "You are provided with a GitHub commit in this format:\n",
    "Commit Message: \"\"\"the commit message written by the author\"\"\"\n",
    "Original Code: \"\"\"the code before the code modificaton\"\"\"\n",
    "Modified Code: \"\"\"the code after the code modification\"\"\"\n",
    "Code Diff : \"\"\"the diff between the original and the modified code\"\"\"\n",
    "\n",
    "The commit is implementing a code optimization to improve software performance or resource utilization.\n",
    "\"\n",
    "Your task is to meticulously examine the commit message, the original code, the modified code, and the differences between the original and modified code (code diff) to understand the improvements in terms of  performance or resource usage. Focus primarily on the changes made to the code as well as the commit message to grasp how they improve performance or resource usage. Your goal is to understand:\"\n",
    "\n",
    "1) The root cause of inefficiency in the original code that necessitated these optimizations.\n",
    "2) The optimization implemented in the revised code, including a deeper understanding on how the modification addresses the identified inefficiencies.\n",
    "\n",
    "Your output should be structured to clearly present:\n",
    "Root Cause of Inefficiency: Explain the specific performance or resource inefficiency issues found in the original code and their root causes.\n",
    "Optimization Strategy: Based on the provided commit and modified code, elaborate the strategies to overcome the root cause of the inefficiencies, detailing the rationale and significance of each optimization. Explain the optimization such a way that one can implement the code modification by following the strategy. Use the \"related notes\" section to better explain the commit if required.\n",
    "\n",
    "- Commit Message: \n",
    "{commit_message}\n",
    "\n",
    "- Original Code:\n",
    "```{Original_Code}```\n",
    "\n",
    "- Modified Code:\n",
    "```{Modified_Code}```\n",
    "\n",
    "Code Diff:\n",
    "```{Code_Diff}```\n",
    "\n",
    "Model Response: '''\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print('Processing {}'.format(i))\n",
    "    original_code = temp_df.loc[i, 'diff_before']\n",
    "    modified_code = temp_df.loc[i, 'diff_after']\n",
    "    commit_message = temp_df.loc[i, 'commit_message']\n",
    "    code_diff=temp_df.loc[i,'diff']\n",
    "    \n",
    "    prompt = prompt_template.format(Original_Code=original_code, Modified_Code=modified_code, commit_message=commit_message,Code_Diff= code_diff)\n",
    "    \n",
    "    # Assuming the `model` and `tokenizer` are set up for generating responses based on the prompt\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "            [{'role': 'user', 'content': prompt}],\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_new_tokens=2046,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    analysis = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "    \n",
    "    batched_predictions.append(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41aa5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['pl_nl']=batched_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990d06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "commit_url        0\n",
       "commit_message    0\n",
       "diff_before       0\n",
       "diff_after        0\n",
       "diff              0\n",
       "pred_primary      0\n",
       "pred_secondary    0\n",
       "Quality           0\n",
       "pl_nl             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eeaedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting explanation to code for sample 0\n",
      "Converting explanation to code for sample 1\n",
      "Converting explanation to code for sample 2\n",
      "Converting explanation to code for sample 3\n",
      "Converting explanation to code for sample 4\n",
      "Converting explanation to code for sample 5\n",
      "Converting explanation to code for sample 6\n",
      "Converting explanation to code for sample 7\n",
      "Converting explanation to code for sample 8\n",
      "Converting explanation to code for sample 9\n",
      "Converting explanation to code for sample 10\n",
      "Converting explanation to code for sample 11\n",
      "Converting explanation to code for sample 12\n",
      "Converting explanation to code for sample 13\n",
      "Converting explanation to code for sample 14\n",
      "Converting explanation to code for sample 15\n",
      "Converting explanation to code for sample 16\n",
      "Converting explanation to code for sample 17\n",
      "Converting explanation to code for sample 18\n",
      "Converting explanation to code for sample 19\n",
      "Converting explanation to code for sample 20\n",
      "Converting explanation to code for sample 21\n",
      "Converting explanation to code for sample 22\n",
      "Converting explanation to code for sample 23\n",
      "Converting explanation to code for sample 24\n",
      "Converting explanation to code for sample 25\n",
      "Converting explanation to code for sample 26\n",
      "Converting explanation to code for sample 27\n",
      "Converting explanation to code for sample 28\n",
      "Converting explanation to code for sample 29\n",
      "Converting explanation to code for sample 30\n"
     ]
    }
   ],
   "source": [
    "conversion_prompt_template = '''\n",
    "You are provided with an explanation of a code optimization and the original code. Your task is to generate the optimized code based on the explanation. Here are the details:\n",
    "\n",
    "Explanation: \n",
    "{explanation}\n",
    "\n",
    "Original Code:\n",
    "```{original_code}```\n",
    "\n",
    "Your task is to generate the optimized code that implements the given explanation. The optimized code should reflect the improvements described in the explanation.\n",
    "\n",
    "Optimized Code: '''\n",
    "\n",
    "# List to store the new code predictions\n",
    "new_code_predictions = []\n",
    "\n",
    "# Process each explanation to generate the optimized code\n",
    "for i in range(len(temp_df)):\n",
    "    print('Converting explanation to code for sample {}'.format(i))\n",
    "    explanation = temp_df.loc[i, 'pl_nl']\n",
    "    original_code = temp_df.loc[i, 'diff_before']\n",
    "    \n",
    "    prompt = conversion_prompt_template.format(explanation=explanation, original_code=original_code)\n",
    "    \n",
    "    # Generate the optimized code based on the explanation\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        [{'role': 'user', 'content': prompt}],\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=2046,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    optimized_code = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "    \n",
    "    new_code_predictions.append(optimized_code)\n",
    "\n",
    "# Store the optimized code in a new column in the dataframe\n",
    "temp_df['optimized_code'] = new_code_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9951c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an example of what the optimized code could look like in Python:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from scipy.sparse import diags\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.metrics.pairwise import rbf_kernel\n",
      "\n",
      "def segment_mesh(mesh, k, coefficients, action):\n",
      "    \"\"\"Segments the given mesh into k clusters using RBF K-means and performs the given action for each cluster\n",
      "    \"\"\"\n",
      "\n",
      "    # set coefficients\n",
      "    global delta\n",
      "    global eta\n",
      "    delta, eta = coefficients\n",
      "\n",
      "    # affinity matrix\n",
      "    W = rbf_kernel(mesh)\n",
      "    print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
      "    \n",
      "    # graph laplacian\n",
      "    row_sums = W.sum(1)\n",
      "    Dsqrt = diags(np.power(row_sums, -0.5).tolist()[0])\n",
      "    L = Dsqrt.dot(W).dot(Dsqrt)\n",
      "    \n",
      "    print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
      "    \n",
      "    # get eigenvectors\n",
      "    _, V = np.linalg.eigh(L)\n",
      "    \n",
      "    print(\"mesh_segmentation: Preparing kmeans...\")\n",
      "    \n",
      "    # compute association matrix\n",
      "    Q = V.dot(V.transpose())\n",
      "    Q = rbf_kernel(Q)\n",
      "\n",
      "    # apply kmeans\n",
      "    kmeans = KMeans(n_clusters=k, random_state=0).fit(Q)\n",
      "    idx = kmeans.labels_\n",
      "\n",
      "    print(\"mesh_segmentation: Done clustering!\")\n",
      "    \n",
      "    # perform action with the clustering result\n",
      "    if action:\n",
      "        action(mesh, k, idx)\n",
      "```\n",
      "\n",
      "In this optimized code, instead of a dense diagonal scaling matrix for the degrees, we are using a sparse diagonal scaling matrix from `scipy.sparse.diags` which saves a lot of memory and prevents unnecessary re-calculation of the sqrt of the diagonal entries. The same operation can be done using `numpy.power` function which performs the power operation element-wise on the array, and `numpy.linalg.eigh` calculates eigenvalues and eigenvectors of the square Hermitian or symmetric matrix, and `sklearn.cluster.KMeans` applies K-means clustering. RBF kernel is a function that measures the similarity of two points. It's a non-linear kernel that's useful when we have features that are not linearly separable or have more complex structures.\n"
     ]
    }
   ],
   "source": [
    "print(temp_df['optimized_code'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6473c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Cause of Inefficiency: The root cause of inefficiency in the original code lies in the computation of the graph laplacian. The original implementation first computes the degree matrix and then applies it to the affinity matrix to obtain the graph laplacian. This leads to high computational costs for large matrices.\n",
      "\n",
      "Optimization Strategy: \n",
      "1. Improved Efficiency: To improve performance, the modified code calculates the degree matrix and the graph laplacian in a more efficient manner. It first computes the square root of the reciprocal of the sum of entries in each row of the affinity matrix, and then multiplies the original affinity matrix by the degree matrices and then transpose-multiplies them to obtain the graph laplacian. This significantly reduces the computational complexity of the computation. \n",
      "2. Simplified Code: The code diff clearly shows the simplification of the code by using numpy broadcasting operations. This reduces the number of lines of code and makes the code easier to read and understand.\n",
      "\n",
      "Use the \"related notes\" section to explain the commit: \n",
      "The initial implementation of the code was inefficient due to its reliance on the creation of a dense diagonal scaling matrix, followed by dot products between this matrix and the affinity matrix. The modified code takes advantage of numpy's efficient broadcasting operations, resulting in a more streamlined, readable, and efficient implementation.\n",
      "\n",
      "Additionally, the root cause of the efficiency issue lies in the use of the dot product to scale the degree matrix and the affinity matrix before computing the graph laplacian. By replacing the dot product with multiplication and transposition operations, the code reduces the computational complexity significantly.\n"
     ]
    }
   ],
   "source": [
    "print(temp_df['pl_nl'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ee676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def segment_mesh(mesh, k, coefficients, action):\n",
      "  \"\"\"Segments the given mesh into k clusters and performs the given\n",
      "  action for each cluster\n",
      "  \"\"\"\n",
      " \n",
      "  # set coefficients\n",
      "  global delta\n",
      "  global eta\n",
      "  delta, eta = coefficients\n",
      " \n",
      "  # affinity matrix\n",
      "  W = _create_affinity_matrix(mesh)\n",
      "  print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
      "  # degree matrix\n",
      "  Dsqrt = numpy.diag([math.sqrt(1/entry) for entry in W.sum(1)])\n",
      "  # graph laplacian\n",
      "  L = Dsqrt.dot(W.dot(Dsqrt))\n",
      " \n",
      "  print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
      "  # get eigenvectors\n",
      "  l,V = scipy.linalg.eigh(L, eigvals = (L.shape[0] - k, L.shape[0] - 1))\n",
      "  # normalize each column to unit length\n",
      "  V = V / [numpy.linalg.norm(column) for column in V.transpose()]\n",
      " \n",
      "  print(\"mesh_segmentation: Preparing kmeans...\")\n",
      "  # compute association matrix\n",
      "  Q = V.dot(V.transpose())\n",
      "  # compute initial guess for clustering\n",
      "  initial_clusters = _initial_guess(Q, k)\n",
      " \n",
      "  print(\"mesh_segmentation: Applying kmeans...\")\n",
      "  # apply kmeans\n",
      "  cluster_res,_ = scipy.cluster.vq.kmeans(V, V[initial_clusters,:])\n",
      "  # get identification vector\n",
      "  idx,_ = scipy.cluster.vq.vq(V, cluster_res)\n",
      " \n",
      "  print(\"mesh_segmentation: Done clustering!\")\n",
      "  # perform action with the clustering result\n",
      "  if action:\n",
      "  action(mesh, k, idx)\n"
     ]
    }
   ],
   "source": [
    "print(temp_df['diff_before'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f526a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def segment_mesh(mesh, k, coefficients, action):\n",
      "  \"\"\"Segments the given mesh into k clusters and performs the given\n",
      "  action for each cluster\n",
      "  \"\"\"\n",
      " \n",
      "  # set coefficients\n",
      "  global delta\n",
      "  global eta\n",
      "  delta, eta = coefficients\n",
      " \n",
      "  # affinity matrix\n",
      "  W = _create_affinity_matrix(mesh)\n",
      "  print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
      "  # degree matrix\n",
      "  Dsqrt = numpy.sqrt(numpy.reciprocal(W.sum(1)))\n",
      "  # graph laplacian\n",
      "  L = ((W * Dsqrt).transpose() * Dsqrt).transpose()\n",
      " \n",
      "  print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
      "  # get eigenvectors\n",
      "  l,V = scipy.linalg.eigh(L, eigvals = (L.shape[0] - k, L.shape[0] - 1))\n",
      "  # normalize each column to unit length\n",
      "  V = V / [numpy.linalg.norm(column) for column in V.transpose()]\n",
      " \n",
      "  print(\"mesh_segmentation: Preparing kmeans...\")\n",
      "  # compute association matrix\n",
      "  Q = V.dot(V.transpose())\n",
      "  # compute initial guess for clustering\n",
      "  initial_clusters = _initial_guess(Q, k)\n",
      " \n",
      "  print(\"mesh_segmentation: Applying kmeans...\")\n",
      "  # apply kmeans\n",
      "  cluster_res,_ = scipy.cluster.vq.kmeans(V, V[initial_clusters,:])\n",
      "  # get identification vector\n",
      "  idx,_ = scipy.cluster.vq.vq(V, cluster_res)\n",
      " \n",
      "  print(\"mesh_segmentation: Done clustering!\")\n",
      "  # perform action with the clustering result\n",
      "  if action:\n",
      "  action(mesh, k, idx)\n"
     ]
    }
   ],
   "source": [
    "print(temp_df['diff_after'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e14c29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/kugelrund/mesh_segmentation/commit/d97ba5446e96ef6cab24bd41f9dbf655f4a26a1f'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df['commit_url'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcce2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('Nxcode-CQ-7B-orpo_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abe116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
