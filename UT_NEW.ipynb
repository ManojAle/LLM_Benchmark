{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13851462",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e93e90",
   "metadata": {},
   "source": [
    "### code before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6a3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Execution time: 5.716378 seconds\n",
      "Run 2:\n",
      "Execution time: 5.662655 seconds\n",
      "Run 3:\n",
      "Execution time: 5.724205 seconds\n",
      "Run 4:\n",
      "Execution time: 5.771606 seconds\n",
      "Run 5:\n",
      "Execution time: 5.632283 seconds\n",
      "Execution times for 5 runs:\n",
      "Run 1: 5.716378 seconds\n",
      "Run 2: 5.662655 seconds\n",
      "Run 3: 5.724205 seconds\n",
      "Run 4: 5.771606 seconds\n",
      "Run 5: 5.632283 seconds\n",
      "Total execution time for 5 runs: 28.507593 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "class MultiVector:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MultiVector):\n",
    "            return self.layout == other.layout\n",
    "        return False\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def _newMV(self, dtype):\n",
    "        # Dummy implementation for testing purposes\n",
    "        return np.zeros((), dtype=dtype)\n",
    "\n",
    "    def _checkOther(self, other, coerce=True) -> Tuple['MultiVector', bool]:\n",
    "        \"\"\"Ensure that the other argument has the same Layout or coerce value if\n",
    "        necessary/requested.\n",
    "      \n",
    "        _checkOther(other, coerce=True) --> newOther, isMultiVector\n",
    "        \"\"\"\n",
    "        if isinstance(other, numbers.Number):\n",
    "            if coerce:\n",
    "                # numeric scalar\n",
    "                newOther = self._newMV(dtype=np.result_type(other))\n",
    "                newOther[()] = other\n",
    "                return newOther, True\n",
    "            else:\n",
    "                return other, False\n",
    "        \n",
    "        elif isinstance(other, MultiVector):\n",
    "            if other.layout != self.layout:\n",
    "                raise ValueError(\n",
    "                    \"cannot operate on MultiVectors with different Layouts\")\n",
    "            else:\n",
    "                return other, True\n",
    "        else:\n",
    "            return other, False\n",
    "\n",
    "# Test cases\n",
    "def run_tests():\n",
    "    layout1 = 'layout1'\n",
    "    layout2 = 'layout2'\n",
    "    obj = MyClass(layout1)\n",
    "    mv1 = MultiVector(layout1)\n",
    "    mv2 = MultiVector(layout2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(2400000):\n",
    "        # Test: same layout multivector\n",
    "        result, isMultiVector = obj._checkOther(mv1)\n",
    "        assert isMultiVector == True, \"Test failed: same layout multivector\"\n",
    "        assert result == mv1, \"Test failed: same layout multivector\"\n",
    "\n",
    "        # Test: different layout multivector\n",
    "        try:\n",
    "            obj._checkOther(mv2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"Test failed: different layout multivector\"\n",
    "\n",
    "        # Test: number with coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=True)\n",
    "        assert isMultiVector == True, \"Test failed: number with coerce\"\n",
    "        assert result[()] == 5, \"Test failed: number with coerce\"\n",
    "\n",
    "        # Test: number without coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=False)\n",
    "        assert isMultiVector == False, \"Test failed: number without coerce\"\n",
    "        assert result == 5, \"Test failed: number without coerce\"\n",
    "\n",
    "        # Test: other type\n",
    "        result, isMultiVector = obj._checkOther(\"string\")\n",
    "        assert isMultiVector == False, \"Test failed: other type\"\n",
    "        assert result == \"string\", \"Test failed: other type\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "# Run the tests 5 times and record the timing\n",
    "timings = []\n",
    "total_start_time = time.time()\n",
    "for i in range(5):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    execution_time = run_tests()\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    timings.append(execution_time)\n",
    "total_end_time = time.time()\n",
    "total_execution_time = total_end_time - total_start_time\n",
    "\n",
    "print(\"Execution times for 5 runs:\")\n",
    "for i, timing in enumerate(timings, 1):\n",
    "    print(f\"Run {i}: {timing:.6f} seconds\")\n",
    "print(f\"Total execution time for 5 runs: {total_execution_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f1a687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7015186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28.507593/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5bfbc",
   "metadata": {},
   "source": [
    "### code after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f387b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Execution time: 5.070971 seconds\n",
      "Run 2:\n",
      "Execution time: 5.037501 seconds\n",
      "Run 3:\n",
      "Execution time: 5.032831 seconds\n",
      "Run 4:\n",
      "Execution time: 4.994346 seconds\n",
      "Run 5:\n",
      "Execution time: 4.921144 seconds\n",
      "Execution times for 5 runs:\n",
      "Run 1: 5.070971 seconds\n",
      "Run 2: 5.037501 seconds\n",
      "Run 3: 5.032831 seconds\n",
      "Run 4: 4.994346 seconds\n",
      "Run 5: 4.921144 seconds\n",
      "Total execution time for 5 runs: 25.057335 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "class MultiVector:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MultiVector):\n",
    "            return self.layout == other.layout\n",
    "        return False\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def _newMV(self, dtype):\n",
    "        # Dummy implementation for testing purposes\n",
    "        return np.zeros((), dtype=dtype)\n",
    "\n",
    "    def _checkOther(self, other, coerce=True) -> Tuple['MultiVector', bool]:\n",
    "        if isinstance(other, MultiVector):\n",
    "            if other.layout != self.layout:\n",
    "                raise ValueError(\"cannot operate on MultiVectors with different Layouts\")\n",
    "            else:\n",
    "                return other, True\n",
    "        elif isinstance(other, numbers.Number):\n",
    "            if coerce:\n",
    "                # numeric scalar\n",
    "                newOther = self._newMV(dtype=np.result_type(other))\n",
    "                newOther[()] = other\n",
    "                return newOther, True\n",
    "            else:\n",
    "                return other, False\n",
    "        else:\n",
    "            return other, False\n",
    "\n",
    "# Test cases\n",
    "def run_tests():\n",
    "    layout1 = 'layout1'\n",
    "    layout2 = 'layout2'\n",
    "    obj = MyClass(layout1)\n",
    "    mv1 = MultiVector(layout1)\n",
    "    mv2 = MultiVector(layout2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(2400000):\n",
    "        # Test: same layout multivector\n",
    "        result, isMultiVector = obj._checkOther(mv1)\n",
    "        assert isMultiVector == True, \"Test failed: same layout multivector\"\n",
    "        assert result == mv1, \"Test failed: same layout multivector\"\n",
    "\n",
    "        # Test: different layout multivector\n",
    "        try:\n",
    "            obj._checkOther(mv2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"Test failed: different layout multivector\"\n",
    "\n",
    "        # Test: number with coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=True)\n",
    "        assert isMultiVector == True, \"Test failed: number with coerce\"\n",
    "        assert result[()] == 5, \"Test failed: number with coerce\"\n",
    "\n",
    "        # Test: number without coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=False)\n",
    "        assert isMultiVector == False, \"Test failed: number without coerce\"\n",
    "        assert result == 5, \"Test failed: number without coerce\"\n",
    "\n",
    "        # Test: other type\n",
    "        result, isMultiVector = obj._checkOther(\"string\")\n",
    "        assert isMultiVector == False, \"Test failed: other type\"\n",
    "        assert result == \"string\", \"Test failed: other type\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "# Run the tests 5 times and record the timing\n",
    "timings = []\n",
    "total_start_time = time.time()\n",
    "for i in range(5):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    execution_time = run_tests()\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    timings.append(execution_time)\n",
    "total_end_time = time.time()\n",
    "total_execution_time = total_end_time - total_start_time\n",
    "\n",
    "print(\"Execution times for 5 runs:\")\n",
    "for i, timing in enumerate(timings, 1):\n",
    "    print(f\"Run {i}: {timing:.6f} seconds\")\n",
    "print(f\"Total execution time for 5 runs: {total_execution_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26b24b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.011467"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.057335/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbea1f",
   "metadata": {},
   "source": [
    "### Artigenz coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69202be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Execution time: 5.265656 seconds\n",
      "Run 2:\n",
      "Execution time: 5.228992 seconds\n",
      "Run 3:\n",
      "Execution time: 5.135853 seconds\n",
      "Run 4:\n",
      "Execution time: 5.188086 seconds\n",
      "Run 5:\n",
      "Execution time: 5.123402 seconds\n",
      "Execution times for 5 runs:\n",
      "Run 1: 5.265656 seconds\n",
      "Run 2: 5.228992 seconds\n",
      "Run 3: 5.135853 seconds\n",
      "Run 4: 5.188086 seconds\n",
      "Run 5: 5.123402 seconds\n",
      "Total execution time for 5 runs: 25.942564 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "class MultiVector:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MultiVector):\n",
    "            return self.layout == other.layout\n",
    "        return False\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def _newMV(self, dtype):\n",
    "        # Dummy implementation for testing purposes\n",
    "        return np.zeros((), dtype=dtype)\n",
    "\n",
    "    def _checkOther(self, other, coerce=True) -> Tuple['MultiVector', bool]:\n",
    "        \"\"\"\n",
    "        Ensure that the other argument has the same Layout or coerce value if\n",
    "        necessary/requested.\n",
    "        \n",
    "        Parameters:\n",
    "        other (MultiVector or number): The other argument to check.\n",
    "        coerce (bool): If True, will coerce numeric values to MultiVector.\n",
    "        \n",
    "        Returns:\n",
    "        Tuple[MultiVector, bool]: A tuple containing the potentially coerced other argument \n",
    "                                  and a boolean indicating if it's a MultiVector.\n",
    "        \"\"\"\n",
    "        if isinstance(other, MultiVector):\n",
    "            if other.layout != self.layout:\n",
    "                raise ValueError(\"cannot operate on MultiVectors with different Layouts\")\n",
    "            else:\n",
    "                return other, True\n",
    "        elif isinstance(other, numbers.Number):\n",
    "            if coerce:\n",
    "                # numeric scalar\n",
    "                newOther = self._newMV(dtype=np.result_type(other))\n",
    "                newOther[()] = other\n",
    "                return newOther, True\n",
    "            else:\n",
    "                return other, False\n",
    "        else:\n",
    "            return other, False\n",
    "\n",
    "# Test cases\n",
    "def run_tests():\n",
    "    layout1 = 'layout1'\n",
    "    layout2 = 'layout2'\n",
    "    obj = MyClass(layout1)\n",
    "    mv1 = MultiVector(layout1)\n",
    "    mv2 = MultiVector(layout2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(2400000):\n",
    "        # Test: same layout multivector\n",
    "        result, isMultiVector = obj._checkOther(mv1)\n",
    "        assert isMultiVector == True, \"Test failed: same layout multivector\"\n",
    "        assert result == mv1, \"Test failed: same layout multivector\"\n",
    "\n",
    "        # Test: different layout multivector\n",
    "        try:\n",
    "            obj._checkOther(mv2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"Test failed: different layout multivector\"\n",
    "\n",
    "        # Test: number with coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=True)\n",
    "        assert isMultiVector == True, \"Test failed: number with coerce\"\n",
    "        assert result[()] == 5, \"Test failed: number with coerce\"\n",
    "\n",
    "        # Test: number without coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=False)\n",
    "        assert isMultiVector == False, \"Test failed: number without coerce\"\n",
    "        assert result == 5, \"Test failed: number without coerce\"\n",
    "\n",
    "        # Test: other type\n",
    "        result, isMultiVector = obj._checkOther(\"string\")\n",
    "        assert isMultiVector == False, \"Test failed: other type\"\n",
    "        assert result == \"string\", \"Test failed: other type\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "# Run the tests 5 times and record the timing\n",
    "timings = []\n",
    "total_start_time = time.time()\n",
    "for i in range(5):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    execution_time = run_tests()\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    timings.append(execution_time)\n",
    "total_end_time = time.time()\n",
    "total_execution_time = total_end_time - total_start_time\n",
    "\n",
    "print(\"Execution times for 5 runs:\")\n",
    "for i, timing in enumerate(timings, 1):\n",
    "    print(f\"Run {i}: {timing:.6f} seconds\")\n",
    "print(f\"Total execution time for 5 runs: {total_execution_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5079eea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.188000000000001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.94/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc19477",
   "metadata": {},
   "source": [
    "### CodeGwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d066e4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Execution time: 5.021347 seconds\n",
      "Run 2:\n",
      "Execution time: 4.966520 seconds\n",
      "Run 3:\n",
      "Execution time: 4.974625 seconds\n",
      "Run 4:\n",
      "Execution time: 5.038281 seconds\n",
      "Run 5:\n",
      "Execution time: 5.005708 seconds\n",
      "Execution times for 5 runs:\n",
      "Run 1: 5.021347 seconds\n",
      "Run 2: 4.966520 seconds\n",
      "Run 3: 4.974625 seconds\n",
      "Run 4: 5.038281 seconds\n",
      "Run 5: 5.005708 seconds\n",
      "Total execution time for 5 runs: 25.007361 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "class MultiVector:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MultiVector):\n",
    "            return self.layout == other.layout\n",
    "        return False\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def _newMV(self, dtype):\n",
    "        # Dummy implementation for testing purposes\n",
    "        return np.zeros((), dtype=dtype)\n",
    "\n",
    "    def _checkOther(self, other, coerce=True) -> Tuple['MultiVector', bool]:\n",
    "        \"\"\"Ensure that the other argument has the same Layout or coerce value if\n",
    "        necessary/requested.\n",
    "\n",
    "        _checkOther(other, coerce=True) --> newOther, isMultiVector\n",
    "        \"\"\"\n",
    "        if isinstance(other, MultiVector):\n",
    "            if other.layout != self.layout:\n",
    "                raise ValueError(\n",
    "                    \"cannot operate on MultiVectors with different Layouts\")\n",
    "            else:\n",
    "                return other, True\n",
    "        elif isinstance(other, numbers.Number):\n",
    "            if coerce:\n",
    "                # numeric scalar\n",
    "                newOther = self._newMV(dtype=np.result_type(other))\n",
    "                newOther[()] = other\n",
    "                return newOther, True\n",
    "            else:\n",
    "                return other, False\n",
    "        else:\n",
    "            return other, False\n",
    "\n",
    "# Test cases\n",
    "def run_tests():\n",
    "    layout1 = 'layout1'\n",
    "    layout2 = 'layout2'\n",
    "    obj = MyClass(layout1)\n",
    "    mv1 = MultiVector(layout1)\n",
    "    mv2 = MultiVector(layout2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(2400000):\n",
    "        # Test: same layout multivector\n",
    "        result, isMultiVector = obj._checkOther(mv1)\n",
    "        assert isMultiVector == True, \"Test failed: same layout multivector\"\n",
    "        assert result == mv1, \"Test failed: same layout multivector\"\n",
    "\n",
    "        # Test: different layout multivector\n",
    "        try:\n",
    "            obj._checkOther(mv2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"Test failed: different layout multivector\"\n",
    "\n",
    "        # Test: number with coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=True)\n",
    "        assert isMultiVector == True, \"Test failed: number with coerce\"\n",
    "        assert result[()] == 5, \"Test failed: number with coerce\"\n",
    "\n",
    "        # Test: number without coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=False)\n",
    "        assert isMultiVector == False, \"Test failed: number without coerce\"\n",
    "        assert result == 5, \"Test failed: number without coerce\"\n",
    "\n",
    "        # Test: other type\n",
    "        result, isMultiVector = obj._checkOther(\"string\")\n",
    "        assert isMultiVector == False, \"Test failed: other type\"\n",
    "        assert result == \"string\", \"Test failed: other type\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "# Run the tests 5 times and record the timing\n",
    "timings = []\n",
    "total_start_time = time.time()\n",
    "for i in range(5):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    execution_time = run_tests()\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    timings.append(execution_time)\n",
    "total_end_time = time.time()\n",
    "total_execution_time = total_end_time - total_start_time\n",
    "\n",
    "print(\"Execution times for 5 runs:\")\n",
    "for i, timing in enumerate(timings, 1):\n",
    "    print(f\"Run {i}: {timing:.6f} seconds\")\n",
    "print(f\"Total execution time for 5 runs: {total_execution_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb1b8b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0014722"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.007361/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae96cac",
   "metadata": {},
   "source": [
    "### NXCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af02e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Execution time: 4.902303 seconds\n",
      "Run 2:\n",
      "Execution time: 5.010174 seconds\n",
      "Run 3:\n",
      "Execution time: 5.042473 seconds\n",
      "Run 4:\n",
      "Execution time: 5.050134 seconds\n",
      "Run 5:\n",
      "Execution time: 5.049216 seconds\n",
      "Execution times for 5 runs:\n",
      "Run 1: 4.902303 seconds\n",
      "Run 2: 5.010174 seconds\n",
      "Run 3: 5.042473 seconds\n",
      "Run 4: 5.050134 seconds\n",
      "Run 5: 5.049216 seconds\n",
      "Total execution time for 5 runs: 25.054772 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import numbers\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "class MultiVector:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MultiVector):\n",
    "            return self.layout == other.layout\n",
    "        return False\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self, layout):\n",
    "        self.layout = layout\n",
    "\n",
    "    def _newMV(self, dtype):\n",
    "        # Dummy implementation for testing purposes\n",
    "        return np.zeros((), dtype=dtype)\n",
    "\n",
    "    def _checkOther(self, other, coerce=True) -> Tuple['MultiVector', bool]:\n",
    "      \"\"\"Ensure that the other argument has the same Layout or coerce value if\n",
    "      necessary/requested.\n",
    "\n",
    "      _checkOther(other, coerce=True) --> newOther, isMultiVector\n",
    "      \"\"\"\n",
    "      if isinstance(other, MultiVector):\n",
    "        if other.layout != self.layout:\n",
    "            raise ValueError(\n",
    "              \"cannot operate on MultiVectors with different Layouts\")\n",
    "        else:\n",
    "            return other, True\n",
    "      elif isinstance(other, numbers.Number):\n",
    "        if coerce:\n",
    "          # numeric scalar\n",
    "          newOther = self._newMV(dtype=np.result_type(other))\n",
    "          newOther[()] = other\n",
    "          return newOther, True\n",
    "        else:\n",
    "            return other, False\n",
    "      else:\n",
    "        return other, False\n",
    "\n",
    "# Test cases\n",
    "def run_tests():\n",
    "    layout1 = 'layout1'\n",
    "    layout2 = 'layout2'\n",
    "    obj = MyClass(layout1)\n",
    "    mv1 = MultiVector(layout1)\n",
    "    mv2 = MultiVector(layout2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(2400000):\n",
    "        # Test: same layout multivector\n",
    "        result, isMultiVector = obj._checkOther(mv1)\n",
    "        assert isMultiVector == True, \"Test failed: same layout multivector\"\n",
    "        assert result == mv1, \"Test failed: same layout multivector\"\n",
    "\n",
    "        # Test: different layout multivector\n",
    "        try:\n",
    "            obj._checkOther(mv2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            assert False, \"Test failed: different layout multivector\"\n",
    "\n",
    "        # Test: number with coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=True)\n",
    "        assert isMultiVector == True, \"Test failed: number with coerce\"\n",
    "        assert result[()] == 5, \"Test failed: number with coerce\"\n",
    "\n",
    "        # Test: number without coerce\n",
    "        result, isMultiVector = obj._checkOther(5, coerce=False)\n",
    "        assert isMultiVector == False, \"Test failed: number without coerce\"\n",
    "        assert result == 5, \"Test failed: number without coerce\"\n",
    "\n",
    "        # Test: other type\n",
    "        result, isMultiVector = obj._checkOther(\"string\")\n",
    "        assert isMultiVector == False, \"Test failed: other type\"\n",
    "        assert result == \"string\", \"Test failed: other type\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    return execution_time\n",
    "\n",
    "# Run the tests 5 times and record the timing\n",
    "timings = []\n",
    "total_start_time = time.time()\n",
    "for i in range(5):\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    execution_time = run_tests()\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    timings.append(execution_time)\n",
    "total_end_time = time.time()\n",
    "total_execution_time = total_end_time - total_start_time\n",
    "\n",
    "print(\"Execution times for 5 runs:\")\n",
    "for i, timing in enumerate(timings, 1):\n",
    "    print(f\"Run {i}: {timing:.6f} seconds\")\n",
    "print(f\"Total execution time for 5 runs: {total_execution_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f85513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0109544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.054772/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4906c",
   "metadata": {},
   "source": [
    "### Example_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc104d88",
   "metadata": {},
   "source": [
    "### Code Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94c6ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 12.02954888343811 seconds\n",
      "Iteration 2: 12.644598007202148 seconds\n",
      "Iteration 3: 12.098832368850708 seconds\n",
      "Iteration 4: 12.565288543701172 seconds\n",
      "Iteration 5: 12.129426717758179 seconds\n",
      "Times for each iteration: [12.02954888343811, 12.644598007202148, 12.098832368850708, 12.565288543701172, 12.129426717758179]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def applyFilter(input):\n",
    "    output = re.sub('^[\\x00-\\x19\\x7f-\\xff\\n\\s]*[\\x00-\\x19\\x7f-\\xff]', '', input)  # look for starting non-ascii characters\n",
    "    output = re.sub('[\\x00-\\x19\\x7f-\\xff][\\x00-\\x19\\x7f-\\xff\\r\\s]*$', '', output)  # look for trailing non-ascii characters\n",
    "    return output\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "739dd7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.293538904190063"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e951d12",
   "metadata": {},
   "source": [
    "### Code after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad9a707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 5.9411046504974365 seconds\n",
      "Iteration 2: 6.038579940795898 seconds\n",
      "Iteration 3: 6.01921010017395 seconds\n",
      "Iteration 4: 6.0735907554626465 seconds\n",
      "Iteration 5: 6.083346843719482 seconds\n",
      "Times for each iteration: [5.9411046504974365, 6.038579940795898, 6.01921010017395, 6.0735907554626465, 6.083346843719482]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "def applyFilter(input):\n",
    "    if len(input) > 10000000:\n",
    "        return input\n",
    "\n",
    "    # Process to remove starting non-ascii characters\n",
    "    i = 0\n",
    "    while i < len(input):\n",
    "        c = ord(input[i])\n",
    "        if not (0 <= c <= 0x19 or 0x7f <= c <= 0xff or input[i] in ' \\n\\r'):\n",
    "            break\n",
    "        i += 1\n",
    "    input = input[i:]\n",
    "\n",
    "    # Process to remove trailing non-ascii characters\n",
    "    i = len(input) - 1\n",
    "    while i >= 0:\n",
    "        c = ord(input[i])\n",
    "        if not (0 <= c <= 0x19 or 0x7f <= c <= 0xff or input[i] in ' \\n\\r'):\n",
    "            break\n",
    "        i -= 1\n",
    "    input = input[:i+1]\n",
    "\n",
    "    return input\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5efe83ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.031166458129883"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54deef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ca31e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test failed for input: \u0000\u0018test, expected: test, got: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/3349651260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/3349651260.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Run tests 200,000 times for 5 iterations and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Test failed for input: \u0000\u0018test, expected: test, got: "
     ]
    }
   ],
   "source": [
    "def applyFilter(input):\n",
    "    if len(input) > 10000000:  # Check if input length exceeds 10 million characters\n",
    "        return input\n",
    "    output = ''\n",
    "    for char in input:\n",
    "        if char > chr(127):  # Check if character is non-ASCII\n",
    "            output += char\n",
    "    return output\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae0b01",
   "metadata": {},
   "source": [
    "### Artigenz coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e65a46a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test failed for input: \u0000\u0018test, expected: test, got: \u0000\u0018test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/1615588321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/1615588321.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Run tests 200,000 times for 5 iterations and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Test failed for input: \u0000\u0018test, expected: test, got: \u0000\u0018test"
     ]
    }
   ],
   "source": [
    "def applyFilter(input):\n",
    "    if len(input) > 10000000:\n",
    "        return input\n",
    " \n",
    "    for i in range(0, len(input)):\n",
    "        if 0 < ord(input[i]) < 0x19 or 0x7f < ord(input[i]) < 0xff or input[i] in ' \\n\\r':\n",
    "            pass  #cut beginning non-ascii characters\n",
    "        else:\n",
    "            input = input[i:]\n",
    "            break\n",
    " \n",
    "    input = input[::-1]  #reversed\n",
    "    for i in range(0, len(input)):\n",
    "        if 0 < ord(input[i]) < 0x19 or 0x7f < ord(input[i]) < 0xff or input[i] in ' \\n\\r':\n",
    "            pass  #cut trailing non-ascii characters\n",
    "        else:\n",
    "            input = input[i:]\n",
    "            break\n",
    "    output = input[::-1]\n",
    "    return output\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539f3a3",
   "metadata": {},
   "source": [
    "### CodeGwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ffdbe76",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test failed for input: \u0000\u0018test, expected: test, got: tset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/875479005.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/875479005.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Run tests 200,000 times for 5 iterations and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Test failed for input: \u0000\u0018test, expected: test, got: tset"
     ]
    }
   ],
   "source": [
    "def applyFilter(input):\n",
    "    MAX_INPUT_SIZE = 10 * 1000000  # Example threshold for input size (10 million characters)\n",
    "    if len(input) > MAX_INPUT_SIZE:\n",
    "        return input  # Return original input if it exceeds the threshold\n",
    "\n",
    "    left = 0\n",
    "    right = len(input) - 1\n",
    "\n",
    "    # Iteratively trim non-ASCII characters from the beginning of the input\n",
    "    while left <= right and ord(input[left]) < 0x20 or ord(input[left]) > 0x7F:\n",
    "        left += 1\n",
    "\n",
    "    # Iteratively trim non-ASCII characters from the end of the input\n",
    "    while right >= left and ord(input[right]) < 0x20 or ord(input[right]) > 0x7F:\n",
    "        right -= 1\n",
    "\n",
    "    # Reverse the trimmed input to achieve the same functionality as the original code\n",
    "    output = input[left:right+1][::-1]\n",
    "    \n",
    "    return output\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe84fe7",
   "metadata": {},
   "source": [
    "### NXCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd150a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test failed for input: \u0000\u0018test, expected: test, got: \u0000\u0018test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/2530850859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/2530850859.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Run tests 200,000 times for 5 iterations and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Test failed for input: \u0000\u0018test, expected: test, got: \u0000\u0018test"
     ]
    }
   ],
   "source": [
    "def applyFilter(input):\n",
    "    if len(input) > 10000000:\n",
    "        return input\n",
    "\n",
    "    input = trimNonAsciiStart(input)\n",
    "    input = trimNonAsciiEnd(input)\n",
    "    return input\n",
    "\n",
    "@staticmethod\n",
    "def trimNonAsciiStart(input):\n",
    "    for i in range(len(input)):\n",
    "        c = ord(input[i])\n",
    "        if 0 < c < 0x19 or 0x7f < c < 0xff or input[i] in ' \\n\\r':\n",
    "            pass\n",
    "        else:\n",
    "            input = input[i:]\n",
    "            break\n",
    "    return input\n",
    "\n",
    "@staticmethod\n",
    "def trimNonAsciiEnd(input):\n",
    "    input = input[::-1]\n",
    "    for i in range(len(input)):\n",
    "        c = ord(input[i])\n",
    "        if 0 < c < 0x19 or 0x7f < c < 0xff or input[i] in ' \\n\\r':\n",
    "            pass\n",
    "        else:\n",
    "            input = input[i:]\n",
    "            break\n",
    "    return input[::-1]\n",
    "test_cases = [\n",
    "    ('\\x00\\x18test', 'test'),\n",
    "    ('test\\x7f\\xff', 'test'),\n",
    "    ('\\x00\\x18test\\x7f\\xff', 'test'),\n",
    "    ('test', 'test'),\n",
    "    ('', ''),\n",
    "    ('\\x00\\x18\\x7f\\xff', '')\n",
    "]\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    for input_str, expected_output in test_cases:\n",
    "        result = applyFilter(input_str)\n",
    "        assert result == expected_output, f\"Test failed for input: {input_str}, expected: {expected_output}, got: {result}\"\n",
    "\n",
    "# Run tests 200,000 times for 5 iterations and measure time\n",
    "iterations = 200000*10\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc053f23",
   "metadata": {},
   "source": [
    "### Example_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19ad2f",
   "metadata": {},
   "source": [
    "### Code before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce0a4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 16.280226469039917 seconds\n",
      "Iteration 2: 16.289761304855347 seconds\n",
      "Iteration 3: 16.277620315551758 seconds\n",
      "Iteration 4: 16.283669233322144 seconds\n",
      "Iteration 5: 16.29598903656006 seconds\n",
      "Times for each iteration: [16.280226469039917, 16.289761304855347, 16.277620315551758, 16.283669233322144, 16.29598903656006]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "    \"\"\"Segments the given mesh into k clusters and performs the given action for each cluster\"\"\"\n",
    "    global delta\n",
    "    global eta\n",
    "    delta, eta = coefficients\n",
    "\n",
    "    # Affinity matrix\n",
    "    W = _create_affinity_matrix(mesh)\n",
    "    # Degree matrix\n",
    "    Dsqrt = np.diag([math.sqrt(1 / entry) for entry in W.sum(1)])\n",
    "    # Graph laplacian\n",
    "    L = Dsqrt.dot(W.dot(Dsqrt))\n",
    "\n",
    "    # Get eigenvectors\n",
    "    l, V = scipy.linalg.eigh(L, eigvals=(L.shape[0] - k, L.shape[0] - 1))\n",
    "    # Normalize each column to unit length\n",
    "    V = V / np.linalg.norm(V, axis=0)\n",
    "\n",
    "    # Compute association matrix\n",
    "    Q = V.dot(V.T)\n",
    "    # Compute initial guess for clustering\n",
    "    initial_clusters = _initial_guess(Q, k)\n",
    "\n",
    "    # Apply kmeans\n",
    "    cluster_res, _ = scipy.cluster.vq.kmeans(V, V[initial_clusters, :])\n",
    "    # Get identification vector\n",
    "    idx, _ = scipy.cluster.vq.vq(V, cluster_res)\n",
    "\n",
    "    # Perform action with the clustering result\n",
    "    if action:\n",
    "        action(mesh, k, idx)\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5193473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.285453271865844"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31621504",
   "metadata": {},
   "source": [
    "### Code After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60ddaf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 6.9349730014801025 seconds\n",
      "Iteration 2: 6.968623399734497 seconds\n",
      "Iteration 3: 6.965521574020386 seconds\n",
      "Iteration 4: 6.971885919570923 seconds\n",
      "Iteration 5: 7.025038480758667 seconds\n",
      "Times for each iteration: [6.9349730014801025, 6.968623399734497, 6.965521574020386, 6.971885919570923, 7.025038480758667]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "  \"\"\"Segments the given mesh into k clusters and performs the given\n",
    "  action for each cluster\n",
    "  \"\"\"\n",
    " \n",
    "  # set coefficients\n",
    "  global delta\n",
    "  global eta\n",
    "  delta, eta = coefficients\n",
    " \n",
    "  # affinity matrix\n",
    "  W = _create_affinity_matrix(mesh)\n",
    "  #print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
    "  # degree matrix\n",
    "  Dsqrt = numpy.sqrt(numpy.reciprocal(W.sum(1)))\n",
    "  # graph laplacian\n",
    "  L = ((W * Dsqrt).transpose() * Dsqrt).transpose()\n",
    " \n",
    "  #print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
    "  # get eigenvectors\n",
    "  l,V = scipy.linalg.eigh(L, eigvals = (L.shape[0] - k, L.shape[0] - 1))\n",
    "  # normalize each column to unit length\n",
    "  V = V / [numpy.linalg.norm(column) for column in V.transpose()]\n",
    " \n",
    "  #print(\"mesh_segmentation: Preparing kmeans...\")\n",
    "  # compute association matrix\n",
    "  Q = V.dot(V.transpose())\n",
    "  # compute initial guess for clustering\n",
    "  initial_clusters = _initial_guess(Q, k)\n",
    " \n",
    "  #print(\"mesh_segmentation: Applying kmeans...\")\n",
    "  # apply kmeans\n",
    "  cluster_res,_ = scipy.cluster.vq.kmeans(V, V[initial_clusters,:])\n",
    "  # get identification vector\n",
    "  idx,_ = scipy.cluster.vq.vq(V, cluster_res)\n",
    " \n",
    "  #print(\"mesh_segmentation: Done clustering!\")\n",
    "  # perform action with the clustering result\n",
    "  if action:\n",
    "      action(mesh, k, idx)\n",
    "\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b7c235e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.973208475112915"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d67bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce06a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 16.76984405517578 seconds\n",
      "Iteration 2: 16.796743392944336 seconds\n",
      "Iteration 3: 16.785048246383667 seconds\n",
      "Iteration 4: 16.791119813919067 seconds\n",
      "Iteration 5: 16.81922674179077 seconds\n",
      "Times for each iteration: [16.76984405517578, 16.796743392944336, 16.785048246383667, 16.791119813919067, 16.81922674179077]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "    \"\"\"Segments the given mesh into k clusters and performs the given\n",
    "    action for each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # set coefficients\n",
    "    global delta\n",
    "    global eta\n",
    "    delta, eta = coefficients\n",
    "\n",
    "    # affinity matrix\n",
    "    W = _create_affinity_matrix(mesh)\n",
    "    #print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
    "    # degree matrix\n",
    "    Dsqrt = numpy.diag([math.sqrt(1/entry) for entry in W.sum(1)])\n",
    "\n",
    "    # optimized: calculate graph laplacian\n",
    "    L = Dsqrt @ W @ Dsqrt\n",
    "\n",
    "    #print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
    "    # get eigenvectors\n",
    "    l, V = scipy.linalg.eigh(L, eigvals=(L.shape[0] - k, L.shape[0] - 1))\n",
    "    # normalize each column to unit length\n",
    "    V = V / [numpy.linalg.norm(column) for column in V.transpose()]\n",
    "\n",
    "    #print(\"mesh_segmentation: Preparing kmeans...\")\n",
    "    # compute association matrix\n",
    "    Q = V @ V.transpose()\n",
    "    # compute initial guess for clustering\n",
    "    initial_clusters = _initial_guess(Q, k)\n",
    "\n",
    "    #print(\"mesh_segmentation: Applying kmeans...\")\n",
    "    # apply kmeans\n",
    "    cluster_res, _ = scipy.cluster.vq.kmeans(V, V[initial_clusters, :])\n",
    "    # get identification vector\n",
    "    idx, _ = scipy.cluster.vq.vq(V, cluster_res)\n",
    "\n",
    "    #print(\"mesh_segmentation: Done clustering!\")\n",
    "    # perform action with the clustering result\n",
    "    if action:\n",
    "        action(mesh, k, idx)\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9a79cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.792396450042723"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Artigenz Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d5e1d19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rbf_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/762596277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/762596277.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mcoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0msegment_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmock_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Run tests 200,000 times and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/762596277.py\u001b[0m in \u001b[0;36msegment_mesh\u001b[0;34m(mesh, k, coefficients, action)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# affinity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mesh_segmentation: Calculating graph laplacian...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rbf_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "    \"\"\"Segments the given mesh into k clusters using RBF K-means and performs the given action for each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # set coefficients\n",
    "    global delta\n",
    "    global eta\n",
    "    delta, eta = coefficients\n",
    "\n",
    "    # affinity matrix\n",
    "    W = rbf_kernel(mesh)\n",
    "    print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
    "    \n",
    "    # graph laplacian\n",
    "    row_sums = W.sum(1)\n",
    "    Dsqrt = diags(np.power(row_sums, -0.5).tolist()[0])\n",
    "    L = Dsqrt.dot(W).dot(Dsqrt)\n",
    "    \n",
    "    print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
    "    \n",
    "    # get eigenvectors\n",
    "    _, V = np.linalg.eigh(L)\n",
    "    \n",
    "    print(\"mesh_segmentation: Preparing kmeans...\")\n",
    "    \n",
    "    # compute association matrix\n",
    "    Q = V.dot(V.transpose())\n",
    "    Q = rbf_kernel(Q)\n",
    "\n",
    "    # apply kmeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(Q)\n",
    "    idx = kmeans.labels_\n",
    "\n",
    "    print(\"mesh_segmentation: Done clustering!\")\n",
    "    \n",
    "    # perform action with the clustering result\n",
    "    if action:\n",
    "        action(mesh, k, idx)\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CodeGwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49cc4631",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rbf_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/1518228293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/1518228293.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mcoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0msegment_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmock_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Run tests 200,000 times and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/1518228293.py\u001b[0m in \u001b[0;36msegment_mesh\u001b[0;34m(mesh, k, coefficients, action)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# affinity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mesh_segmentation: Calculating graph laplacian...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rbf_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "    \"\"\"Segments the given mesh into k clusters using RBF K-means and performs the given action for each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # set coefficients\n",
    "    global delta\n",
    "    global eta\n",
    "    delta, eta = coefficients\n",
    "\n",
    "    # affinity matrix\n",
    "    W = rbf_kernel(mesh)\n",
    "    print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
    "    \n",
    "    # graph laplacian\n",
    "    row_sums = W.sum(1)\n",
    "    Dsqrt = diags(np.power(row_sums, -0.5).tolist()[0])\n",
    "    L = Dsqrt.dot(W).dot(Dsqrt)\n",
    "    \n",
    "    print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
    "    \n",
    "    # get eigenvectors\n",
    "    _, V = np.linalg.eigh(L)\n",
    "    \n",
    "    print(\"mesh_segmentation: Preparing kmeans...\")\n",
    "    \n",
    "    # compute association matrix\n",
    "    Q = V.dot(V.transpose())\n",
    "    Q = rbf_kernel(Q)\n",
    "\n",
    "    # apply kmeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(Q)\n",
    "    idx = kmeans.labels_\n",
    "\n",
    "    print(\"mesh_segmentation: Done clustering!\")\n",
    "    \n",
    "    # perform action with the clustering result\n",
    "    if action:\n",
    "        action(mesh, k, idx)\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16f435e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1989287/2126616972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mrun_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/2126616972.py\u001b[0m in \u001b[0;36mrun_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mcoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0msegment_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmock_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Run tests 200,000 times and measure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1989287/2126616972.py\u001b[0m in \u001b[0;36msegment_mesh\u001b[0;34m(mesh, k, coefficients, action)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# compute association matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# get eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "\n",
    "### NXCODE\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.cluster.vq\n",
    "import math\n",
    "import time\n",
    "import numpy\n",
    "# Mock implementations with a larger matrix\n",
    "def mock_create_affinity_matrix(mesh):\n",
    "    size = 100  # Adjust size as needed for testing\n",
    "    matrix = np.random.rand(size, size)\n",
    "    return (matrix + matrix.T) / 2  # Ensure the matrix is symmetric\n",
    "\n",
    "def mock_initial_guess(Q, k):\n",
    "    return np.random.choice(Q.shape[0], k, replace=False)\n",
    "\n",
    "def mock_eigh(L, eigvals):\n",
    "    vals = np.random.rand(L.shape[0])\n",
    "    vecs = np.random.rand(L.shape[0], eigvals[1] - eigvals[0] + 1)\n",
    "    return vals, vecs\n",
    "\n",
    "def mock_kmeans(V, initial):\n",
    "    return np.random.rand(V.shape[0], V.shape[1]), None\n",
    "\n",
    "def mock_vq(V, cluster_res):\n",
    "    return np.random.randint(0, cluster_res.shape[0], V.shape[0]), None\n",
    "\n",
    "# Mock action\n",
    "def mock_action(mesh, k, idx):\n",
    "    pass  # No assertion needed for performance testing\n",
    "\n",
    "# Replacing the real functions with mocks\n",
    "_create_affinity_matrix = mock_create_affinity_matrix\n",
    "_initial_guess = mock_initial_guess\n",
    "scipy.linalg.eigh = mock_eigh\n",
    "scipy.cluster.vq.kmeans = mock_kmeans\n",
    "scipy.cluster.vq.vq = mock_vq\n",
    "\n",
    "# Assuming these are defined elsewhere in the actual code\n",
    "\n",
    "def segment_mesh(mesh, k, coefficients, action):\n",
    "    \"\"\"Segments the given mesh into k clusters and performs the given\n",
    "    action for each cluster\n",
    "    \"\"\"\n",
    "    # set coefficients\n",
    "    global delta\n",
    "    global eta\n",
    "    delta, eta = coefficients\n",
    "\n",
    "    # affinity matrix\n",
    "    W = _create_affinity_matrix(mesh)\n",
    "    #print(\"mesh_segmentation: Calculating graph laplacian...\")\n",
    "\n",
    "    # degree matrix\n",
    "    Dsqrt = numpy.sqrt(numpy.reciprocal(W.sum(1)))\n",
    "\n",
    "    # graph laplacian - optimized computation\n",
    "    L_optimized = Dsqrt.T.dot(W.dot(Dsqrt))\n",
    "\n",
    "   #print(\"mesh_segmentation: Calculating eigenvectors...\")\n",
    "\n",
    "    # compute association matrix\n",
    "    Q = L_optimized.dot(L_optimized.T)\n",
    "\n",
    "    # get eigenvectors\n",
    "    l, V = scipy.linalg.eigh(Q, eigvals=(Q.shape[0] - k, Q.shape[0] - 1))\n",
    "\n",
    "    # normalize each column to unit length\n",
    "    V = V / [numpy.linalg.norm(column) for column in V.transpose()]\n",
    "\n",
    "    #print(\"mesh_segmentation: Preparing kmeans...\")\n",
    "\n",
    "    # compute initial guess for clustering\n",
    "    initial_clusters = _initial_guess(Q, k)\n",
    "\n",
    "    #print(\"mesh_segmentation: Applying kmeans...\")\n",
    "\n",
    "    # apply kmeans\n",
    "    cluster_res, _ = scipy.cluster.vq.kmeans(V, V[initial_clusters, :])\n",
    "\n",
    "    # get identification vector\n",
    "    idx, _ = scipy.cluster.vq.vq(V, cluster_res)\n",
    "\n",
    "    #print(\"mesh_segmentation: Done clustering!\")\n",
    "\n",
    "    # perform action with the clustering result\n",
    "    if action:\n",
    "        action(mesh, k, idx)\n",
    "# Function to run the tests\n",
    "def run_tests():\n",
    "    mesh = \"mock_mesh\"\n",
    "    k = 5\n",
    "    coefficients = (0.1, 0.2)\n",
    "    segment_mesh(mesh, k, coefficients, mock_action)\n",
    "\n",
    "# Run tests 200,000 times and measure time\n",
    "iterations = 60000\n",
    "total_runs = 5\n",
    "\n",
    "times = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        run_tests()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration:\", times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb9f3e",
   "metadata": {},
   "source": [
    "### Example_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d993b3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.995752000808716"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32dbe3b",
   "metadata": {},
   "source": [
    "### code before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00c3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 for v1: 6.11 seconds\n",
      "Iteration 2 for v1: 6.20 seconds\n",
      "Iteration 3 for v1: 6.21 seconds\n",
      "Iteration 4 for v1: 6.11 seconds\n",
      "Iteration 5 for v1: 6.12 seconds\n",
      "Iteration 1 for v2: 4.22 seconds\n",
      "Iteration 2 for v2: 4.23 seconds\n",
      "Iteration 3 for v2: 4.19 seconds\n",
      "Iteration 4 for v2: 4.20 seconds\n",
      "Iteration 5 for v2: 4.20 seconds\n",
      "Times for each iteration of v1: [6.110483169555664, 6.195840120315552, 6.206468105316162, 6.11121129989624, 6.117157936096191]\n",
      "Times for each iteration of v2: [4.224043369293213, 4.227595329284668, 4.193343877792358, 4.19836688041687, 4.201219320297241]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    unicode = unicode\n",
    "    basestring = basestring\n",
    "else:\n",
    "    unicode = str\n",
    "    basestring = (str, bytes)\n",
    "\n",
    "class ServiceManager:\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "\n",
    "    def decoding(self, name):\n",
    "        return name\n",
    "\n",
    "    # First implementation\n",
    "    def getServiceName_v1(self, name):\n",
    "        if isinstance(name, unicode):\n",
    "            pass\n",
    "        elif isinstance(name, (basestring, str)):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.c.Win32_Service(StartMode=\"Auto\", State=\"Stopped\"):\n",
    "            if name.lower() == s.Name.lower() or name.lower() == s.Caption.lower():\n",
    "                return s.Name, s.Caption, s.DisplayName\n",
    "        return None\n",
    "\n",
    "    # Second implementation\n",
    "    def getServiceName_v2(self, name):\n",
    "        if isinstance(name, unicode):\n",
    "            pass\n",
    "        elif isinstance(name, (basestring, str)):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.c.Win32_Service(Name=name):\n",
    "            return s.Name, s.Caption, s.DisplayName\n",
    "\n",
    "class MockService:\n",
    "    def __init__(self, name, caption, display_name):\n",
    "        self.Name = name\n",
    "        self.Caption = caption\n",
    "        self.DisplayName = display_name\n",
    "\n",
    "class MockC:\n",
    "    def Win32_Service(self, StartMode=None, State=None, Name=None):\n",
    "        services = [\n",
    "            MockService(\"Service1\", \"Service 1\", \"Service One\"),\n",
    "            MockService(\"Service2\", \"Service 2\", \"Service Two\"),\n",
    "            MockService(\"Service3\", \"Service 3\", \"Service Three\"),\n",
    "            MockService(\"Service4\", \"Service 4\", \"Service Four\"),\n",
    "            MockService(\"Service5\", \"Service 5\", \"Service Five\"),\n",
    "        ]\n",
    "        if Name:\n",
    "            return [s for s in services if s.Name == Name]\n",
    "        return services\n",
    "\n",
    "def test_getServiceName_v1(service_manager):\n",
    "    # Test with name matching Name attribute\n",
    "    result = service_manager.getServiceName_v1(\"Service1\")\n",
    "    assert result == (\"Service1\", \"Service 1\", \"Service One\"), f\"Expected ('Service1', 'Service 1', 'Service One'), but got {result}\"\n",
    "\n",
    "    # Test with name matching Caption attribute\n",
    "    result = service_manager.getServiceName_v1(\"Service 2\")\n",
    "    assert result == (\"Service2\", \"Service 2\", \"Service Two\"), f\"Expected ('Service2', 'Service 2', 'Service Two'), but got {result}\"\n",
    "\n",
    "    # Test with name that does not match\n",
    "    result = service_manager.getServiceName_v1(\"Service6\")\n",
    "    assert result is None, f\"Expected None, but got {result}\"\n",
    "\n",
    "    # Test with different case\n",
    "    result = service_manager.getServiceName_v1(\"service3\")\n",
    "    assert result == (\"Service3\", \"Service 3\", \"Service Three\"), f\"Expected ('Service3', 'Service 3', 'Service Three'), but got {result}\"\n",
    "\n",
    "def test_getServiceName_v2(service_manager):\n",
    "    # Test with name matching Name attribute\n",
    "    result = service_manager.getServiceName_v2(\"Service1\")\n",
    "    assert result == (\"Service1\", \"Service 1\", \"Service One\"), f\"Expected ('Service1', 'Service 1', 'Service One'), but got {result}\"\n",
    "\n",
    "    # Test with name that does not match\n",
    "    result = service_manager.getServiceName_v2(\"Service6\")\n",
    "    assert result is None, f\"Expected None, but got {result}\"\n",
    "\n",
    "    # Test with different case (should not match in v2)\n",
    "    result = service_manager.getServiceName_v2(\"service3\")\n",
    "    assert result is None, f\"Expected None, but got {result}\"\n",
    "\n",
    "# Function to run the tests repeatedly\n",
    "def run_tests(test_function, iterations):\n",
    "    mock_c = MockC()\n",
    "    service_manager = ServiceManager(mock_c)\n",
    "    for _ in range(iterations):\n",
    "        test_function(service_manager)\n",
    "\n",
    "# Running the tests 12,000 times in 5 iterations for both versions and measuring the time\n",
    "iterations_per_run = 1200000\n",
    "total_runs = 5\n",
    "\n",
    "times_v1 = []\n",
    "times_v2 = []\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    run_tests(test_getServiceName_v1, iterations_per_run)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times_v1.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1} for v1: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "for i in range(total_runs):\n",
    "    start_time = time.time()\n",
    "    run_tests(test_getServiceName_v2, iterations_per_run)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times_v2.append(elapsed_time)\n",
    "    print(f\"Iteration {i + 1} for v2: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Output the times\n",
    "print(\"Times for each iteration of v1:\", times_v1)\n",
    "print(\"Times for each iteration of v2:\", times_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74769001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.148232126235962"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis=[6.110483169555664, 6.195840120315552, 6.206468105316162, 6.11121129989624, 6.117157936096191]\n",
    "sum(lis)/len(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05cbfa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getServiceName_1 times: [6.887456874945201, 6.92972218291834, 6.981187824974768, 6.959391387063079, 6.990892750909552]\n",
      "getServiceName_1 average time: 6.94973 seconds\n",
      "getServiceName_2 times: [5.6921897570136935, 5.720444465056062, 5.705263642012142, 5.698652061983012, 5.715962699032389]\n",
      "getServiceName_2 average time: 5.70650 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "class ServiceTester:\n",
    "    def __init__(self, services):\n",
    "        self.c = self\n",
    "        self.services = services\n",
    "\n",
    "    def Win32_Service(self, **kwargs):\n",
    "        if \"StartMode\" in kwargs and \"State\" in kwargs:\n",
    "            return (s for s in self.services if s[\"StartMode\"] == kwargs[\"StartMode\"] and s[\"State\"] == kwargs[\"State\"])\n",
    "        elif \"Name\" in kwargs:\n",
    "            return (s for s in self.services if s[\"Name\"] == kwargs[\"Name\"])\n",
    "        return []\n",
    "\n",
    "    def decoding(self, name):\n",
    "        # No Decoding\n",
    "        return name\n",
    "\n",
    "    def getServiceName_1(self, name):\n",
    "        if isinstance(name, str):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.Win32_Service(StartMode=\"Auto\", State=\"Stopped\"):\n",
    "            if name.lower() == s[\"Name\"].lower() or name.lower() == s[\"Caption\"].lower():\n",
    "                return s[\"Name\"], s[\"Caption\"], s[\"DisplayName\"]\n",
    "        return None\n",
    "\n",
    "    def getServiceName_2(self, name):\n",
    "        if isinstance(name, str):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.Win32_Service(Name=name):\n",
    "            return s[\"Name\"], s[\"Caption\"], s[\"DisplayName\"]\n",
    "        return None\n",
    "\n",
    "# Example services list for testing\n",
    "services = [\n",
    "    {\"Name\": \"ServiceA\", \"Caption\": \"Service A\", \"DisplayName\": \"Service A\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "    {\"Name\": \"ServiceB\", \"Caption\": \"Service B\", \"DisplayName\": \"Service B\", \"StartMode\": \"Manual\", \"State\": \"Running\"},\n",
    "    {\"Name\": \"ServiceC\", \"Caption\": \"Service C\", \"DisplayName\": \"Service C\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "]\n",
    "\n",
    "tester = ServiceTester(services)\n",
    "name_to_test = \"ServiceA\"\n",
    "\n",
    "# Run each function 10000 times for 5 iterations\n",
    "iterations = 5\n",
    "num_runs = 10000000\n",
    "\n",
    "times_1 = []\n",
    "times_2 = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\n",
    "    times_1.append(time_1)\n",
    "    time_2 = timeit.timeit(lambda: tester.getServiceName_2(name_to_test), number=num_runs)\n",
    "    times_2.append(time_2)\n",
    "\n",
    "# Calculate average times\n",
    "average_time_1 = np.mean(times_1)\n",
    "average_time_2 = np.mean(times_2)\n",
    "\n",
    "print(f\"getServiceName_1 times: {times_1}\")\n",
    "print(f\"getServiceName_1 average time: {average_time_1:.5f} seconds\")\n",
    "\n",
    "print(f\"getServiceName_2 times: {times_2}\")\n",
    "print(f\"getServiceName_2 average time: {average_time_2:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466343b",
   "metadata": {},
   "source": [
    "### CodeGwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d23de0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getServiceName_1 times: [7.044512672931887, 6.911133390967734, 6.913519063964486, 6.897041957941838, 6.888211584999226]\n",
      "getServiceName_1 average time: 6.93088 seconds\n",
      "getServiceName_2 times: [0.7261747240554541, 0.7236093010287732, 0.7250296300044283, 0.7268282979493961, 0.725898452103138]\n",
      "getServiceName_2 average time: 0.72551 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "class ServiceTester:\n",
    "    def __init__(self, services):\n",
    "        self.c = self\n",
    "        self.services = services\n",
    "\n",
    "    def Win32_Service(self, **kwargs):\n",
    "        if \"StartMode\" in kwargs and \"State\" in kwargs:\n",
    "            return (s for s in self.services if s[\"StartMode\"] == kwargs[\"StartMode\"] and s[\"State\"] == kwargs[\"State\"])\n",
    "        elif \"Name\" in kwargs:\n",
    "            return (s for s in self.services if s[\"Name\"] == kwargs[\"Name\"])\n",
    "        return []\n",
    "\n",
    "    def decoding(self, name):\n",
    "        # Replace with the actual decoding logic\n",
    "        return name\n",
    "\n",
    "    def getServiceName_1(self, name):\n",
    "        if isinstance(name, str):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.Win32_Service(StartMode=\"Auto\", State=\"Stopped\"):\n",
    "            if name.lower() == s[\"Name\"].lower() or name.lower() == s[\"Caption\"].lower():\n",
    "                return s[\"Name\"], s[\"Caption\"], s[\"DisplayName\"]\n",
    "        return None\n",
    "\n",
    "    def getServiceName_2(self, name):\n",
    "        if isinstance(name, unicode):\n",
    "            pass\n",
    "        elif isinstance(name, (basestring, str)):\n",
    "            name = decoding(name)\n",
    "            for s in self.c.Win32_Service():\n",
    "                if s['Name'].lower() == name.lower():\n",
    "                    return s.Name, s.Caption, s.DisplayName\n",
    "# Example services list for testing\n",
    "services = [\n",
    "    {\"Name\": \"ServiceA\", \"Caption\": \"Service A\", \"DisplayName\": \"Service A\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "    {\"Name\": \"ServiceB\", \"Caption\": \"Service B\", \"DisplayName\": \"Service B\", \"StartMode\": \"Manual\", \"State\": \"Running\"},\n",
    "    {\"Name\": \"ServiceC\", \"Caption\": \"Service C\", \"DisplayName\": \"Service C\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "]\n",
    "\n",
    "tester = ServiceTester(services)\n",
    "name_to_test = \"ServiceA\"\n",
    "\n",
    "# Run each function 10000 times for 5 iterations\n",
    "iterations = 5\n",
    "num_runs = 10000000\n",
    "\n",
    "times_1 = []\n",
    "times_2 = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\n",
    "    times_1.append(time_1)\n",
    "    time_2 = timeit.timeit(lambda: tester.getServiceName_2(name_to_test), number=num_runs)\n",
    "    times_2.append(time_2)\n",
    "\n",
    "# Calculate average times\n",
    "average_time_1 = np.mean(times_1)\n",
    "average_time_2 = np.mean(times_2)\n",
    "\n",
    "print(f\"getServiceName_1 times: {times_1}\")\n",
    "print(f\"getServiceName_1 average time: {average_time_1:.5f} seconds\")\n",
    "\n",
    "print(f\"getServiceName_2 times: {times_2}\")\n",
    "print(f\"getServiceName_2 average time: {average_time_2:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c714856",
   "metadata": {},
   "source": [
    "### Artigenz Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452fc88b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'first'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2005631/3882420815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#times_1.append(time_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtime_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetServiceName_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mtimes_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    232\u001b[0m            number=default_number, globals=None):\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2005631/3882420815.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#times_1.append(time_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtime_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetServiceName_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mtimes_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2005631/3882420815.py\u001b[0m in \u001b[0;36mgetServiceName_2\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbasestring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWin32_Service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Access the specific service object by its name directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCaption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplayName\u001b[0m  \u001b[0;31m# Return the attributes of the specific service object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'first'"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "class ServiceTester:\n",
    "    def __init__(self, services):\n",
    "        self.c = self\n",
    "        self.services = services\n",
    "\n",
    "    def Win32_Service(self, **kwargs):\n",
    "        if \"StartMode\" in kwargs and \"State\" in kwargs:\n",
    "            return (s for s in self.services if s[\"StartMode\"] == kwargs[\"StartMode\"] and s[\"State\"] == kwargs[\"State\"])\n",
    "        elif \"Name\" in kwargs:\n",
    "            return (s for s in self.services if s[\"Name\"] == kwargs[\"Name\"])\n",
    "        return []\n",
    "\n",
    "    def decoding(self, name):\n",
    "        # Replace with the actual decoding logic\n",
    "        return name\n",
    "\n",
    "    def getServiceName_1(self, name):\n",
    "        if isinstance(name, str):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.Win32_Service(StartMode=\"Auto\", State=\"Stopped\"):\n",
    "            if name.lower() == s[\"Name\"].lower() or name.lower() == s[\"Caption\"].lower():\n",
    "                return s[\"Name\"], s[\"Caption\"], s[\"DisplayName\"]\n",
    "        return None\n",
    "\n",
    "    def getServiceName_2(self, name):\n",
    "        if isinstance(name, unicode):\n",
    "            pass\n",
    "        elif isinstance(name, (basestring, str)):\n",
    "            name = decoding(name)\n",
    "        service = self.c.Win32_Service(Name=name).first()  # Access the specific service object by its name directly\n",
    "        if service:\n",
    "            return service.Name, service.Caption, service.DisplayName  # Return the attributes of the specific service object\n",
    "        else:\n",
    "            return None \n",
    "# Example services list for testing\n",
    "services = [\n",
    "    {\"Name\": \"ServiceA\", \"Caption\": \"Service A\", \"DisplayName\": \"Service A\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "    {\"Name\": \"ServiceB\", \"Caption\": \"Service B\", \"DisplayName\": \"Service B\", \"StartMode\": \"Manual\", \"State\": \"Running\"},\n",
    "    {\"Name\": \"ServiceC\", \"Caption\": \"Service C\", \"DisplayName\": \"Service C\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "]\n",
    "\n",
    "tester = ServiceTester(services)\n",
    "name_to_test = \"ServiceA\"\n",
    "\n",
    "# Run each function 10000 times for 5 iterations\n",
    "iterations = 5\n",
    "num_runs = 10000000\n",
    "\n",
    "times_1 = []\n",
    "times_2 = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    #time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\n",
    "    #times_1.append(time_1)\n",
    "    time_2 = timeit.timeit(lambda: tester.getServiceName_2(name_to_test), number=num_runs)\n",
    "    times_2.append(time_2)\n",
    "\n",
    "# Calculate average times\n",
    "average_time_1 = np.mean(times_1)\n",
    "average_time_2 = np.mean(times_2)\n",
    "\n",
    "print(f\"getServiceName_1 times: {times_1}\")\n",
    "print(f\"getServiceName_1 average time: {average_time_1:.5f} seconds\")\n",
    "\n",
    "print(f\"getServiceName_2 times: {times_2}\")\n",
    "print(f\"getServiceName_2 average time: {average_time_2:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823b4fbd",
   "metadata": {},
   "source": [
    "### codeGwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d58a0f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2005631/4173698572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#times_1.append(time_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtime_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetServiceName_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtimes_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    232\u001b[0m            number=default_number, globals=None):\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2005631/4173698572.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#times_1.append(time_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtime_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetServiceName_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtimes_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2005631/4173698572.py\u001b[0m in \u001b[0;36mgetServiceName_2\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWin32_Service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCaption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplayName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Example services list for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'Name'"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "class ServiceTester:\n",
    "    def __init__(self, services):\n",
    "        self.c = self\n",
    "        self.services = services\n",
    "\n",
    "    def Win32_Service(self, **kwargs):\n",
    "        if \"StartMode\" in kwargs and \"State\" in kwargs:\n",
    "            return (s for s in self.services if s[\"StartMode\"] == kwargs[\"StartMode\"] and s[\"State\"] == kwargs[\"State\"])\n",
    "        elif \"Name\" in kwargs:\n",
    "            return (s for s in self.services if s[\"Name\"] == kwargs[\"Name\"])\n",
    "        return []\n",
    "\n",
    "    def decoding(self, name):\n",
    "        # Replace with the actual decoding logic\n",
    "        return name\n",
    "\n",
    "    def getServiceName_1(self, name):\n",
    "        if isinstance(name, str):\n",
    "            name = self.decoding(name)\n",
    "        for s in self.Win32_Service(StartMode=\"Auto\", State=\"Stopped\"):\n",
    "            if name.lower() == s[\"Name\"].lower() or name.lower() == s[\"Caption\"].lower():\n",
    "                return s[\"Name\"], s[\"Caption\"], s[\"DisplayName\"]\n",
    "        return None\n",
    "\n",
    "    def getServiceName_2(self, name):\n",
    "        if isinstance(name, unicode):\n",
    "            pass\n",
    "        elif isinstance(name, (basestring, str)):\n",
    "            name = decoding(name)\n",
    "        for s in self.c.Win32_Service(Name=name):\n",
    "             return s.Name, s.Caption, s.DisplayName\n",
    "\n",
    "# Example services list for testing\n",
    "services = [\n",
    "    {\"Name\": \"ServiceA\", \"Caption\": \"Service A\", \"DisplayName\": \"Service A\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "    {\"Name\": \"ServiceB\", \"Caption\": \"Service B\", \"DisplayName\": \"Service B\", \"StartMode\": \"Manual\", \"State\": \"Running\"},\n",
    "    {\"Name\": \"ServiceC\", \"Caption\": \"Service C\", \"DisplayName\": \"Service C\", \"StartMode\": \"Auto\", \"State\": \"Stopped\"},\n",
    "]\n",
    "\n",
    "tester = ServiceTester(services)\n",
    "name_to_test = \"ServiceA\"\n",
    "\n",
    "# Run each function 10000 times for 5 iterations\n",
    "iterations = 5\n",
    "num_runs = 10000000\n",
    "\n",
    "times_1 = []\n",
    "times_2 = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    #time_1 = timeit.timeit(lambda: tester.getServiceName_1(name_to_test), number=num_runs)\n",
    "    #times_1.append(time_1)\n",
    "    time_2 = timeit.timeit(lambda: tester.getServiceName_2(name_to_test), number=num_runs)\n",
    "    times_2.append(time_2)\n",
    "\n",
    "# Calculate average times\n",
    "average_time_1 = np.mean(times_1)\n",
    "average_time_2 = np.mean(times_2)\n",
    "\n",
    "print(f\"getServiceName_1 times: {times_1}\")\n",
    "print(f\"getServiceName_1 average time: {average_time_1:.5f} seconds\")\n",
    "\n",
    "print(f\"getServiceName_2 times: {times_2}\")\n",
    "print(f\"getServiceName_2 average time: {average_time_2:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b533a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example _5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6837a",
   "metadata": {},
   "source": [
    "### code before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7addeb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by numpy_gemm_BEFORE: 8.52547812461853\n",
      "Time taken by numpy_gemm_AFTER: 5.018169164657593\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "import time\n",
    "\n",
    "def numpy_gemm_BEFORE(\n",
    "    a: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    c: Optional[np.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\"\"\"\n",
    "\n",
    "    a_prime = np.transpose(a) if transA else a\n",
    "    b_prime = np.transpose(b) if transB else b\n",
    "    c_prime: Union[np.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    y = alpha * np.matmul(a_prime, b_prime) + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "def numpy_gemm_AFTER(\n",
    "    a: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    c: Optional[np.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\"\"\"\n",
    "\n",
    "    a_prime = np.transpose(a) if transA else a\n",
    "    b_prime = np.transpose(b) if transB else b\n",
    "    c_prime: Union[np.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    y = np.matmul(a_prime, b_prime)\n",
    "    y = y + c_prime if len(np.argwhere(c_prime != 0)) > 0 else y\n",
    "    return (y,)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = np.random.rand(1000, 1000)\n",
    "    b = np.random.rand(1000, 1000)\n",
    "    c = np.zeros((1000, 1000))\n",
    "    start_time_before = time.time()\n",
    "    for _ in range(800):\n",
    "      numpy_gemm_BEFORE(a, b, c)\n",
    "\n",
    "      #  test_with_c_Before()\n",
    "    end_time_after = time.time()\n",
    "    print(\"Time taken by numpy_gemm_BEFORE:\", end_time_after - start_time_before)\n",
    "\n",
    "    start_time_before = time.time()\n",
    "    for _ in range(800):\n",
    "      numpy_gemm_AFTER(a, b, c)\n",
    "\n",
    "    end_time_after = time.time()\n",
    "    print(\"Time taken by numpy_gemm_AFTER:\", end_time_after - start_time_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349c3e6",
   "metadata": {},
   "source": [
    "### artigenz coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b35ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by numpy_gemm_BEFORE: 8.56234073638916\n",
      "Time taken by numpy_gemm_AFTER: 9.820056915283203\n",
      "Time taken by numpy_gemm_BEFORE: 8.611958026885986\n",
      "Time taken by numpy_gemm_AFTER: 9.762579441070557\n",
      "Time taken by numpy_gemm_BEFORE: 8.61674427986145\n",
      "Time taken by numpy_gemm_AFTER: 9.776850938796997\n",
      "Time taken by numpy_gemm_BEFORE: 8.627703428268433\n",
      "Time taken by numpy_gemm_AFTER: 9.780990362167358\n",
      "Time taken by numpy_gemm_BEFORE: 8.566827297210693\n",
      "Time taken by numpy_gemm_AFTER: 9.765060901641846\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "import time\n",
    "import numpy\n",
    "def numpy_gemm_BEFORE(\n",
    "    a: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    c: Optional[np.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\"\"\"\n",
    "\n",
    "    a_prime = np.transpose(a) if transA else a\n",
    "    b_prime = np.transpose(b) if transB else b\n",
    "    c_prime: Union[np.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    y = alpha * np.matmul(a_prime, b_prime) + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "def numpy_gemm_AFTER(\n",
    "    a: numpy.ndarray,\n",
    "    b: numpy.ndarray,\n",
    "    c: Optional[numpy.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    ") -> Tuple[numpy.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\n",
    "\n",
    "    Args:\n",
    "    a (numpy.ndarray): Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M)\n",
    "    if transA is non-zero.\n",
    "    b (numpy.ndarray): Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K)\n",
    "    if transB is non-zero.\n",
    "    c (Optional[numpy.ndarray]): Optional input tensor C. If not specified, the\n",
    "    computation is done as if C is a scalar 0. The shape of C should be unidirectional\n",
    "    broadcastable to (M, N).\n",
    "    Defaults to None.\n",
    "    alpha (float): Scalar multiplier for the product of input tensors A * B.\n",
    "    Defaults to 1.0.\n",
    "    beta (float): Scalar multiplier for input tensor C.\n",
    "    Defaults to 1.0.\n",
    "    transA (int): Whether A should be transposed. The type is kept as int as it's the\n",
    "    type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "    Defaults to 0.\n",
    "    transB (int): Whether B should be transposed. The type is kept as int as it's the\n",
    "    type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "    Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[numpy.ndarray]: The tuple containing the result tensor\n",
    "    \"\"\"\n",
    "\n",
    "    a_prime = numpy.transpose(a) if transA else a\n",
    "    b_prime = numpy.transpose(b) if transB else b\n",
    "    if c is not None:\n",
    "        c_prime = c \n",
    "    else:\n",
    "        c_prime = 0.0\n",
    "\n",
    "    y = numpy.matmul(a_prime, b_prime)\n",
    "    y = alpha * y + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = np.random.rand(1000, 1000)\n",
    "    b = np.random.rand(1000, 1000)\n",
    "    c = np.zeros((1000, 1000))\n",
    "    for i in range(5):\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_BEFORE(a, b, c)\n",
    "\n",
    "          #  test_with_c_Before()\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_BEFORE:\", end_time_after - start_time_before)\n",
    "\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_AFTER(a, b, c)\n",
    "\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_AFTER:\", end_time_after - start_time_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de963523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code gwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06003058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by numpy_gemm_BEFORE: 12.54791808128357\n",
      "Time taken by numpy_gemm_AFTER: 7.920638799667358\n",
      "Time taken by numpy_gemm_BEFORE: 12.566787481307983\n",
      "Time taken by numpy_gemm_AFTER: 7.9736878871917725\n",
      "Time taken by numpy_gemm_BEFORE: 12.660543203353882\n",
      "Time taken by numpy_gemm_AFTER: 7.980003118515015\n",
      "Time taken by numpy_gemm_BEFORE: 12.689164876937866\n",
      "Time taken by numpy_gemm_AFTER: 8.016119718551636\n",
      "Time taken by numpy_gemm_BEFORE: 12.673482656478882\n",
      "Time taken by numpy_gemm_AFTER: 7.958872079849243\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "import time\n",
    "import numpy\n",
    "def numpy_gemm_BEFORE(\n",
    "    a: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    c: Optional[np.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\"\"\"\n",
    "\n",
    "    a_prime = np.transpose(a) if transA else a\n",
    "    b_prime = np.transpose(b) if transB else b\n",
    "    c_prime: Union[np.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    y = alpha * np.matmul(a_prime, b_prime) + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "def numpy_gemm_AFTER(\n",
    "  a: numpy.ndarray,\n",
    "  b: numpy.ndarray,\n",
    "  c: Optional[numpy.ndarray] = None,\n",
    "  alpha: float = 1.0,\n",
    "  beta: float = 1.0,\n",
    "  transA: int = 0,\n",
    "  transB: int = 0,\n",
    " ) -> Tuple[numpy.ndarray]:\n",
    "  \"\"\"Compute Gemm in numpy according to ONNX spec.\n",
    " \n",
    "  See https://github.com/onnx/onnx/blob/main/docs/Changelog.md#Gemm-13\n",
    " \n",
    "  Args:\n",
    "  a (numpy.ndarray): Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M)\n",
    "  if transA is non-zero.\n",
    "  b (numpy.ndarray): Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K)\n",
    "  if transB is non-zero.\n",
    "  c (Optional[numpy.ndarray]): Optional input tensor C. If not specified, the\n",
    "  computation is done as if C is a scalar 0. The shape of C should be unidirectional\n",
    "  broadcastable to (M, N).\n",
    "  Defaults to None.\n",
    "  alpha (float): Scalar multiplier for the product of input tensors A * B.\n",
    "  Defaults to 1.0.\n",
    "  beta (float): Scalar multiplier for input tensor C.\n",
    "  Defaults to 1.0.\n",
    "  transA (int): Whether A should be transposed. The type is kept as int as it's the\n",
    "  type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "  Defaults to 0.\n",
    "  transB (int): Whether B should be transposed. The type is kept as int as it's the\n",
    "  type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "  Defaults to 0.\n",
    " \n",
    "  Returns:\n",
    "  Tuple[numpy.ndarray]: The tuple containing the result tensor\n",
    "  \"\"\"\n",
    " \n",
    "  a_prime = numpy.transpose(a) if transA else a\n",
    "  b_prime = numpy.transpose(b) if transB else b\n",
    "  c_prime: Union[numpy.ndarray, float] = c if c is not None else 0.0\n",
    " \n",
    "  y = alpha * numpy.dot(a_prime, b_prime) + beta * c_prime  # Direct calculation without using matmul\n",
    " \n",
    "  return (y,)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = np.random.rand(1000, 1000)\n",
    "    b = np.random.rand(1000, 1000)\n",
    "    c = np.zeros((1000, 1000))\n",
    "    for i in range(5):\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_BEFORE(a, b, c)\n",
    "\n",
    "          #  test_with_c_Before()\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_BEFORE:\", end_time_after - start_time_before)\n",
    "\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_AFTER(a, b, c)\n",
    "\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_AFTER:\", end_time_after - start_time_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d6c3b",
   "metadata": {},
   "source": [
    "### nxcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca47e16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by numpy_gemm_BEFORE: 12.612847566604614\n",
      "Time taken by numpy_gemm_AFTER: 3.063680410385132\n",
      "Time taken by numpy_gemm_BEFORE: 12.637491226196289\n",
      "Time taken by numpy_gemm_AFTER: 3.0998332500457764\n",
      "Time taken by numpy_gemm_BEFORE: 12.617098808288574\n",
      "Time taken by numpy_gemm_AFTER: 3.092900276184082\n",
      "Time taken by numpy_gemm_BEFORE: 12.652971506118774\n",
      "Time taken by numpy_gemm_AFTER: 3.064734697341919\n",
      "Time taken by numpy_gemm_BEFORE: 12.658419609069824\n",
      "Time taken by numpy_gemm_AFTER: 3.119481325149536\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "import time\n",
    "import numpy\n",
    "def numpy_gemm_BEFORE(\n",
    "    a: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    c: Optional[np.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec.\"\"\"\n",
    "\n",
    "    a_prime = np.transpose(a) if transA else a\n",
    "    b_prime = np.transpose(b) if transB else b\n",
    "    c_prime: Union[np.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    y = alpha * np.matmul(a_prime, b_prime) + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "def numpy_gemm_AFTER(\n",
    "    a: numpy.ndarray,\n",
    "    b: numpy.ndarray,\n",
    "    c: Optional[numpy.ndarray] = None,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    transA: int = 0,\n",
    "    transB: int = 0,\n",
    ") -> Tuple[numpy.ndarray]:\n",
    "    \"\"\"Compute Gemm in numpy according to ONNX spec with optimized strategy for multiplication.\n",
    "\n",
    "    See https://github.com/onnx/onnx/blob/main/docs/Changelog.md#Gemm-13\n",
    "\n",
    "    Args:\n",
    "    a (numpy.ndarray): Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M)\n",
    "    if transA is non-zero.\n",
    "    b (numpy.ndarray): Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K)\n",
    "    if transB is non-zero.\n",
    "    c (Optional[numpy.ndarray]): Optional input tensor C. If not specified, the\n",
    "    computation is done as if C is a scalar 0. The shape of C should be unidirectional\n",
    "    broadcastable to (M, N).\n",
    "    Defaults to None.\n",
    "    alpha (float): Scalar multiplier for the product of input tensors A * B.\n",
    "    Defaults to 1.0.\n",
    "    beta (float): Scalar multiplier for input tensor C.\n",
    "    Defaults to 1.0.\n",
    "    transA (int): Whether A should be transposed. The type is kept as int as it's the\n",
    "    type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "    Defaults to 0.\n",
    "    transB (int): Whether B should be transposed. The type is kept as int as it's the\n",
    "    type used by ONNX and it can easily be interpreted by python as a boolean.\n",
    "    Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[numpy.ndarray]: The tuple containing the result tensor\n",
    "    \"\"\"\n",
    "\n",
    "    a_prime = numpy.transpose(a) if transA else a\n",
    "    b_prime = numpy.transpose(b) if transB else b\n",
    "    c_prime: Union[numpy.ndarray, float] = c if c is not None else 0.0\n",
    "\n",
    "    if alpha == 1 and beta == 1:\n",
    "        y = a_prime @ b_prime  # Utilizing optimized matrix multiplication\n",
    "    else:\n",
    "        y = alpha * (a_prime @ b_prime) + beta * c_prime\n",
    "\n",
    "    return (y,)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = np.random.rand(1000, 1000)\n",
    "    b = np.random.rand(1000, 1000)\n",
    "    c = np.zeros((1000, 1000))\n",
    "    for i in range(5):\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_BEFORE(a, b, c)\n",
    "\n",
    "          #  test_with_c_Before()\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_BEFORE:\", end_time_after - start_time_before)\n",
    "\n",
    "        start_time_before = time.time()\n",
    "        for _ in range(800):\n",
    "          numpy_gemm_AFTER(a, b, c)\n",
    "\n",
    "        end_time_after = time.time()\n",
    "        print(\"Time taken by numpy_gemm_AFTER:\", end_time_after - start_time_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd22c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
